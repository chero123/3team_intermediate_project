{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345a3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ íŒŒì´ì¬ ê²½ë¡œ: /home/spai0630/workspace/venv/bin/python\n",
      "âœ… pdfplumber ë¡œë“œ ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pdfplumber\n",
    "print(f\"í˜„ì¬ íŒŒì´ì¬ ê²½ë¡œ: {sys.executable}\")\n",
    "print(\"âœ… pdfplumber ë¡œë“œ ì„±ê³µ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c5414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í´ë” ê°ì§€ ì„±ê³µ! íŒŒì¼ ê°œìˆ˜: 101ê°œ\n",
      "ìƒ˜í”Œ íŒŒì¼ëª…: ['á„‰á…¡á„ƒá…¡á†«á„‡á…¥á†¸á„‹á…µá†«á„‹á…¡á„‰á…µá„‹á…¡á„†á…®á†¯á„‹á…±á„‹á…¯á†«á„’á…¬á„‰á…¡á„†á…®á„€á…®á†¨_á„‹á…®á„Œá…³á„‡á…¦á†¨-á„á…µá„…á…³á„€á…µá„Œá…³á„‰á…³á„á…¡á†« á„€á…µá„’á…®á„‡á…§á†«á„’á…ªá„ƒá…¢á„‹á…³á†¼ á„‰á…³.hwp', 'á„á…®á†¨á„‰á…¡á†«á„†á…®á†¯á„‘á…®á†·á„Œá…µá†¯á„‘á…§á†¼á„€á…¡á„‹á…¯á†«_á„á…®á†¨á„‰á…¡á†«á„†á…®á†¯á„‹á…µá„…á…§á†¨á„€á…ªá†«á„…á…µá„‰á…µá„‰á…³á„á…¦á†· á„€á…¢á„‰á…¥á†«(á„Œá…¥á†¼á„‡á…©á„’á…ª á„‰á…¡á„‹á…¥á†¸).hwp', 'á„’á…¡á†«á„€á…®á†¨á„‰á…®á„á…®á†¯á„‹á…µá†¸á„‹á…³á†«á„’á…¢á†¼_(á„€á…µá†«á„€á…³á†¸) á„†á…©á„Œá…¡á†·á„‡á…µá„á…³ á„†á…¡á„‘á…®á„á…© á„Œá…µá„‚á…³á†¼á„’á…§á†¼á„€á…­á„á…©á†¼á„‰á…µá„‰á…³á„á…¦á†·(ITS) á„€á…®á„á…®á†¨á„‰á…¡á„‹á…¥á†¸.hwp']\n",
      "ğŸ“Š CSV ì²« ë²ˆì§¸ íŒŒì¼ëª…: 'í•œì˜ëŒ€í•™_í•œì˜ëŒ€í•™êµ íŠ¹ì„±í™” ë§ì¶¤í˜• êµìœ¡í™˜ê²½ êµ¬ì¶• - íŠ¸ë™ìš´ì˜ í•™ì‚¬ì •ë³´.hwp'\n",
      "ğŸ” ë§¤ì¹­ ê²°ê³¼: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ê²½ë¡œ ë‹¤ì‹œ í™•ì¸\n",
    "BASE_DIR = \"/home/spai0630/workspace/data/original_data\"\n",
    "FILES_DIR = os.path.join(BASE_DIR, \"files\")\n",
    "META_PATH = os.path.join(BASE_DIR, \"data_list.csv\")\n",
    "\n",
    "# 1. í´ë”ì— íŒŒì¼ì´ ì§„ì§œ ìˆëŠ”ì§€ í™•ì¸\n",
    "if os.path.exists(FILES_DIR):\n",
    "    files = os.listdir(FILES_DIR)\n",
    "    print(f\"âœ… í´ë” ê°ì§€ ì„±ê³µ! íŒŒì¼ ê°œìˆ˜: {len(files)}ê°œ\")\n",
    "    print(f\"ìƒ˜í”Œ íŒŒì¼ëª…: {files[:3]}\")\n",
    "else:\n",
    "    print(\"âŒ í´ë” ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "# 2. CSV íŒŒì¼ ë¡œë“œ ë° íŒŒì¼ëª… ë§¤ì¹­ í…ŒìŠ¤íŠ¸\n",
    "df = pd.read_csv(META_PATH)\n",
    "csv_name = df['íŒŒì¼ëª…'].iloc[0]\n",
    "print(f\"ğŸ“Š CSV ì²« ë²ˆì§¸ íŒŒì¼ëª…: '{csv_name}'\")\n",
    "print(f\"ğŸ” ë§¤ì¹­ ê²°ê³¼: {csv_name in files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804c013",
   "metadata": {},
   "source": [
    "pdfplumnerëŠ” pdf ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¼ì„œ í•œê¸€ íŒŒì¼ì„ ëª»ì½ìŒ ê·¸ë˜ì„œ í™•ì¥ì ë¶ˆì¼ì¹˜ ì¡´ì¬ \n",
    "ê·¸ë˜ì„œ pdfë¡œ ëª¨ë“  í•œê¸€íŒŒì¼ì„ ë³€í™˜í•´ì„œ ê¸°ì¡´ ë¡œì§ì„ ì‚¬ìš©í•œë‹¤ê±°ë‚˜ \n",
    "í•œê¸€ ì „ìš© íŒŒì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²• pyhwpx ë‚˜ olefile ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ ì„¤ì¹˜ \n",
    "í˜¹ì€ pdfë§Œ ê°–ê³  ë¨¼ì € rag ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57043cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ [ë§¤ì¹­ ë¶„ì„ ê²°ê³¼]\n",
      "CSV: í•œì˜ëŒ€í•™_í•œì˜ëŒ€í•™êµ íŠ¹ì„±í™” ë§ì¶¤í˜• êµ... | ë§¤ì¹­ ì—¬ë¶€: âŒ\n",
      "CSV: í•œêµ­ì—°êµ¬ì¬ë‹¨_2024ë…„ ëŒ€í•™ì‚°í•™í˜‘ë ¥í™œ... | ë§¤ì¹­ ì—¬ë¶€: âŒ\n",
      "CSV: í•œêµ­ìƒì‚°ê¸°ìˆ ì—°êµ¬ì›_EIP3.0 ê³ ì••ê°€... | ë§¤ì¹­ ì—¬ë¶€: âŒ\n",
      "CSV: ì¸ì²œê´‘ì—­ì‹œ_ë„ì‹œê³„íšìœ„ì›íšŒ í†µí•©ê´€ë¦¬ì‹œìŠ¤... | ë§¤ì¹­ ì—¬ë¶€: âŒ\n",
      "CSV: ê²½ìƒë¶ë„ ë´‰í™”êµ°_ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œ... | ë§¤ì¹­ ì—¬ë¶€: âŒ\n",
      "\n",
      "ğŸ“Š í˜„ì¬ í´ë” êµ¬ì„± -> HWP: 96ê°œ, PDF: 4ê°œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. í™•ì¥ìë¥¼ ì œê±°í•œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°\n",
    "file_list = os.listdir(FILES_DIR)\n",
    "file_names_only = [os.path.splitext(f)[0] for f in file_list]\n",
    "\n",
    "# 2. CSV ë°ì´í„° í™•ì¸\n",
    "df = pd.read_csv(META_PATH)\n",
    "\n",
    "print(\"ğŸ“‹ [ë§¤ì¹­ ë¶„ì„ ê²°ê³¼]\")\n",
    "for i in range(5):\n",
    "    csv_name = df['íŒŒì¼ëª…'].iloc[i]\n",
    "    csv_name_no_ext = os.path.splitext(csv_name)[0].strip()\n",
    "    \n",
    "    # ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "    match = csv_name_no_ext in file_names_only\n",
    "    print(f\"CSV: {csv_name_no_ext[:20]}... | ë§¤ì¹­ ì—¬ë¶€: {'âœ…' if match else 'âŒ'}\")\n",
    "\n",
    "# 3. HWP íŒŒì¼ ê°œìˆ˜ í™•ì¸\n",
    "hwp_count = len([f for f in file_list if f.endswith('.hwp')])\n",
    "pdf_count = len([f for f in file_list if f.endswith('.pdf')])\n",
    "print(f\"\\nğŸ“Š í˜„ì¬ í´ë” êµ¬ì„± -> HWP: {hwp_count}ê°œ, PDF: {pdf_count}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6b479",
   "metadata": {},
   "source": [
    "pdf ê°¯ìˆ˜ê°€ í˜„ì €íˆ ì ê¸° ë•Œë¬¸ì— pdfë¡œ ë³€í™˜í•´ì„œ ì‚¬ìš©í•˜ëŠ” ê±´ ë„ˆë¬´ ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ í•œê¸€ ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¸ìŠ¤í†¨í•´ì„œ ì‚¬ìš©í•´ë³´ê¸°ë¡œ í•¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259f1765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting olefile\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Installing collected packages: olefile\n",
      "Successfully installed olefile-0.47\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install olefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b828553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ '/home/spai0630/workspace/data/original_data/files/á„‰á…¡á„ƒá…¡á†«á„‡á…¥á†¸á„‹á…µá†«á„‹á…¡á„‰á…µá„‹á…¡á„†á…®á†¯á„‹á…±á„‹á…¯á†«á„’á…¬á„‰á…¡á„†á…®á„€á…®á†¨_á„‹á…®á„Œá…³á„‡á…¦á†¨-á„á…µá„…á…³á„€á…µá„Œá…³á„‰á…³á„á…¡á†« á„€á…µá„’á…®á„‡á…§á†«á„’á…ªá„ƒá…¢á„‹á…³á†¼ á„‰á…³.hwp' ì¶”ì¶œ ì‹œë„ ì¤‘...\n",
      "Ñ„Â€\u0000\u0000Ñ…É€\u0000\u0000\u0000\u0000Ï¨\u0000Ï¨\u0000Í’\u0000É˜\u0000\u0000\u0000ë£¼\u0000\u0000\u0006Ñ‡Ë°æ¤ç¥\u0000\u0000Ñ®\u0000\u0000á½€\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ä¤€è€ˆè ‚Ã¨Åˆæ€\u0019â”€\u0016áˆ€\u000bé¬€\u0010é¬€\u0010é¬€\u0010\u0000\u0000\u0000\u0000ä¨€ì€ˆ\u0001\u0000\u0000\u0000â¤€Ä€ï¼€ï¿¿å‹¿ãœƒá¬‚Ä\u0001\u0000ä¨€ì€ˆ\u0001\u0000\u0000\u0000â¤€Ä€ï €î€¯åˆ€ãœƒ\u0002Ä€\u0001\u0000ä¬€î€ˆÄ€\u0000è¤€è¤…è¤…è¤…Ü…ä¬€î€ˆÄ€\u0000è¤€è¤…è¤…è¤…Ä…ä¬€î€ˆÄ€\u0000è¤€è¤…è¤…è¤…Ä…äœ€\u0004ææ½¬Ñ£\u0010\u0000\u0000\u0000\u0000äˆ€è€€Ä\u0000\u0000\u0000á €\u0000Ä€\u0000Ä€\u0000\u0000Â€ä€è€„\u0000\u0000à €\u0000ä”€ä€„\u0002\u0000ä€€\u0006î €\u0003î €\u0003åˆ€\u0003å €\u0002\u0000\u0000ï°€Â¸\u0000Ø€äˆ€è€€Ä\u0000\u0000\u0000á €\u0000Ä€\u0000Ä€\u0000\u0000Â€ä€è€„\u0000\u0000à €\u0000ä”€ä€„\u0002\u0000è€€\fî €\u0003î €\u0003åˆ€\u0003å €\u0002\u0000\u0000ï°€Â¸\u0000Ø€äˆ€è€€á„\u0000\u0000â€ˆá €\u0000È€\u0000Ä€\u0000\u0000Â€äŒ€â€„á”‚æ€æ¨p\u0000\u0000\u0000á”€à¬€â€€ç¯g\u0000\u0000\u0000à¬€à´€ä€\u0004\u0001\u0000à €\u0000à €\u0000à¤€\u0000ä”€ä€„\u0002\u0000ì€€\u0012îˆ€#îˆ€#è€€\u001eå €\u0002\u0000\u0000ï°€Â¸\u0000Ø€äœ€è€„æ€æ¨â°\u0000äœ€î€„â€‚ç¯á…§æ©ƒ\u0004\u0000\u0000\u0000â¬€Âšîˆ€#Ä€\u0000\u0000\u0000\u0000\u0000é €ê´€Z\u0000\u0000ä°€â€ˆæ¸æ¯æ¸¤æ¯$\u0000\u0000\u0000\u0000Ä€ä€Â¨îˆ€#â¬€Âšîˆ€#\u0000Ä€\u0000á”€Mï„€\u0011Ä€\u0000\u0000\u0000ï€€?\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ï€€?\u0000\u0000\u0000à¬€æ¿ê —îµ‘?\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ï€€?\u0000\u0000\u0000\u0000\u0000\u0000ï€€?\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ï€€?\u0000\u0000\u0000È€æŒ€ç©æŒ¤ç‰¥é¤¤ê´€ä°š\fæŒ’ç©è ¤ï¿¸ë«¿ï¿¸Ç¿Ä€í€€Â¶î°€1ç¸€Â§î°€1\u0000\u0000$á”€Mï„€\u0011È€\u0000\u0000\u0000ï€€?\u0000\u0000\u0000\u0000\u0000\u0000é· Ã€\u0000\u0000\u0000\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "import olefile\n",
    "import zlib\n",
    "\n",
    "def extract_hwp_text(hwp_path):\n",
    "    f = olefile.OleFileIO(hwp_path)\n",
    "    dirs = f.listdir()\n",
    "\n",
    "    # HWP ë‚´ ë³¸ë¬¸ ìŠ¤íŠ¸ë¦¼(BodyText) ì°¾ê¸°\n",
    "    bodytext = [d for d in dirs if d[0].startswith('BodyText')]\n",
    "    full_text = \"\"\n",
    "\n",
    "    for section in bodytext:\n",
    "        data = f.openstream(section).read()\n",
    "        # ì••ì¶• í•´ì œ (HWPëŠ” ê¸°ë³¸ì ìœ¼ë¡œ zlib ì••ì¶•ë¨)\n",
    "        try:\n",
    "            decompressed = zlib.decompress(data, -15)\n",
    "            full_text += decompressed.decode('utf-16', errors='ignore')\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return full_text\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_hwp = os.path.join(FILES_DIR, file_list[0]) # ì•„ê¹Œ ì°¾ì€ HWP íŒŒì¼\n",
    "if test_hwp.endswith('.hwp'):\n",
    "    print(f\"ğŸ“„ '{test_hwp}' ì¶”ì¶œ ì‹œë„ ì¤‘...\")\n",
    "    print(extract_hwp_text(test_hwp)[:500]) # ì•ë¶€ë¶„ 500ìë§Œ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ce883",
   "metadata": {},
   "source": [
    "olefile ì€ íŒŒì¼ì´ ê°œê°™ì´ ê¹¨ì¡ŒìŒ.\n",
    "ê·¸ë˜ì„œ ë‹¤ë¥¸ íŒ€ì›ë“¤ì´ í™œìš©í•´ë´¤ë‹¤ë˜ hwp5python ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b87a5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement hwp5python (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for hwp5python\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hwp5python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894425da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement hwp5 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for hwp5\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hwp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80d8e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyhwpx\n",
      "  Downloading pyhwpx-1.6.6-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from pyhwpx) (2.4.2)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from pyhwpx) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of pyhwpx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading pyhwpx-1.6.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.6.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.6.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.6.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.6.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.6.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.5.6-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: pip is still looking at multiple versions of pyhwpx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading pyhwpx-1.5.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.5.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.5.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.5.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.5.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading pyhwpx-1.5.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.11-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.10-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.9-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.8-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.7-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.6-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.4.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.3.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.3.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.3.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.3.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.3.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.8-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.7-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.6-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.2.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.7-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.6-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.1.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.0.17-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.0.16-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.0.15-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.0.14-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading pyhwpx-1.0.13-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.12-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.11-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.8-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.7-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.6-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.5-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.4-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.3-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-1.0.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.51.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.51.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.51.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.40-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.39-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.38-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.37-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.36-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.35-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.34-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.33-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.32-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.31-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.30-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.29-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.28-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.27-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.26-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.25-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.24-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.23-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.22-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.21-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.20-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading pyhwpx-0.50.19-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.18-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.17-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.15-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.3-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.50.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.49.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.48.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.47-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.46-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.45-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.44-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.43-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.42-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.41-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.40-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.39-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.38-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.37-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.36-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.35-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.34-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.33-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.32-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.31-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.30-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.28-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.26-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.25-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.24-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.23-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.22-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.21-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.20-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.19-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.18-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.17-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.15-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pyhwpx-0.47.6-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading pyhwpx-0.47.5-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading pyhwpx-0.47.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading pyhwpx-0.47.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading pyhwpx-0.47.2.tar.gz (160 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/spai0630/workspace/venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/spai0630/workspace/venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/spai0630/workspace/venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-qbwqqj2g/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 333, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-qbwqqj2g/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 301, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-qbwqqj2g/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 518, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-qbwqqj2g/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 17, in <module>\n",
      "  \u001b[31m   \u001b[0m RuntimeError: pyhwpxëŠ” Windowsì—ì„œë§Œ ë™ì‘í•©ë‹ˆë‹¤.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31mERROR: Failed to build 'pyhwpx' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyhwpx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cbacb5",
   "metadata": {},
   "source": [
    "ìœˆë„ìš° ë…¸íŠ¸ë¶ì´ ì•„ë‹ˆë¼ì„œ? í•œê¸€ íŒŒì¼ ë¡œë“œ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì‹¤íŒ¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "febc589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ë¡œë“œ ì„±ê³µ: 100ê°œì˜ ëª©ë¡ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "âœ… ë°œê²¬ëœ PDF ê°œìˆ˜: 4ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 20843.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ìµœì¢… ì™„ë£Œ: 0ê±´ì˜ PDFê°€ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. ê²½ë¡œ ì„¤ì • (ì •í™•í•œ spai0630 ê³„ì • ê²½ë¡œ)\n",
    "BASE_DIR = \"/home/spai0630/workspace/data/original_data\"\n",
    "FILES_DIR = os.path.join(BASE_DIR, \"files\")\n",
    "META_PATH = os.path.join(BASE_DIR, \"data_list.csv\")\n",
    "\n",
    "# 2. ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì—¬ê¸°ì„œ df_metaë¥¼ ì •ì˜í•©ë‹ˆë‹¤)\n",
    "if os.path.exists(META_PATH):\n",
    "    df_meta = pd.read_csv(META_PATH)\n",
    "    print(f\"ğŸ“Š CSV ë¡œë“œ ì„±ê³µ: {len(df_meta)}ê°œì˜ ëª©ë¡ì´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# 3. PDF íŒŒì¼ë§Œ ê³¨ë¼ë‚´ì„œ ì²˜ë¦¬\n",
    "results = []\n",
    "if os.path.exists(FILES_DIR):\n",
    "    pdf_files = [f for f in os.listdir(FILES_DIR) if f.lower().endswith('.pdf')]\n",
    "    print(f\"âœ… ë°œê²¬ëœ PDF ê°œìˆ˜: {len(pdf_files)}ê°œ\")\n",
    "\n",
    "    for index, row in tqdm(df_meta.iterrows(), total=len(df_meta)):\n",
    "        f_name = str(row['íŒŒì¼ëª…']).strip() # íŒŒì¼ëª…ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ê³µë°± ì œê±°\n",
    "        if f_name in pdf_files:\n",
    "            f_path = os.path.join(FILES_DIR, f_name)\n",
    "            try:\n",
    "                with pdfplumber.open(f_path) as pdf:\n",
    "                    # ëª¨ë“  í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "                    text = \" \".join([p.extract_text() for p in pdf.pages if p.extract_text()])\n",
    "                    results.append({\n",
    "                        \"ì‚¬ì—…ëª…\": row.get('ì‚¬ì—…ëª…', 'N/A'),\n",
    "                        \"ë°œì£¼ê¸°ê´€\": row.get('ë°œì£¼ê¸°ê´€', 'N/A'),\n",
    "                        \"ë³¸ë¬¸\": text,\n",
    "                        \"íŒŒì¼ëª…\": f_name\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {f_name} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "    # 4. ê²°ê³¼ ì €ì¥\n",
    "    output_path = \"/home/spai0630/workspace/data/processed_pdf_only.jsonl\"\n",
    "    df_result = pd.DataFrame(results)\n",
    "    df_result.to_json(output_path, orient='records', force_ascii=False, lines=True)\n",
    "    print(f\"ğŸš€ ìµœì¢… ì™„ë£Œ: {len(results)}ê±´ì˜ PDFê°€ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"âŒ files í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df31de",
   "metadata": {},
   "source": [
    "ì‚¬ì†Œí•œ ê³µë°±ì´ë‚˜ íŒŒì¼ëª…ì˜ ì°¨ì´ ë•Œë¬¸ì— ë§¤ì¹­ì´ ì´ë¤„ì§€ì§€ ì•Šì•„ì„œ ì‹¤ì œ íŒŒì¼ë“¤ì€ ì„œì¹­ì´ ë˜ì—ˆì§€ë§Œ í†µí•©ì´ ì´ë¤„ì§€ì§€ ì•ŠìŒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd1d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì„œë²„ì— ìˆëŠ” ì‹¤ì œ PDF (4ê°œ): ['á„€á…©á„…á…§á„ƒá…¢á„’á…¡á†¨á„€á…­_á„á…¡á„‰á…¦á„ƒá…¢ á„‘á…©á„á…¥á†¯Â·á„’á…¡á†¨á„‰á…¡ á„Œá…¥á†¼á„‡á…©á„‰á…µá„‰á…³á„á…¦á†· á„€á…®á„á…®á†¨á„‰á…¡á„‹á…¥á†¸.pdf', 'á„€á…µá„á…©á„€á…ªá„’á…¡á†¨á„‹á…§á†«á„€á…®á„‹á…¯á†«_2025á„‚á…§á†«á„ƒá…© á„Œá…®á†¼á„‹á…µá„‹á…©á†«á„€á…¡á„‰á…©á†¨á„€á…µá„‹á…­á†¼ á„€á…³á†¨á„Œá…¥á„‹á…©á†«á„‰á…µá„‰á…³á„á…¦á†· á„‹á…®á†«á„Œá…¥á†« á„‹á…­á†¼á„‹á…§á†¨.pdf', 'á„‰á…¥á„‹á…®á†¯á„‰á…µá„…á…µá†¸á„ƒá…¢á„’á…¡á†¨á„€á…­_[á„‰á…¡á„Œá…¥á†«á„€á…©á†¼á„€á…¢] á„’á…¡á†¨á„‹á…¥á†¸á„‰á…¥á†¼á„á…±á„ƒá…© á„ƒá…¡á„á…¡á„‹á…¯á†« á„Œá…©á†¼á„ƒá…¡á†«á„‡á…®á†«á„‰á…¥á†¨ á„á…©á†¼á„’á…¡á†¸á„‰á…µá„‰á…³á„á…¦á†· 1á„á…¡.pdf', 'á„‰á…¥á„‹á…®á†¯á„á…³á†¨á„‡á…§á†¯á„‰á…µ_2024á„‚á…§á†« á„Œá…µá„ƒá…©á„Œá…¥á†¼á„‡á…© á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†· á„†á…µá†¾ á„Œá…¥á†«á„†á…®á†«á„’á…ªá†¯á„‹á…­á†¼ á„‹á…§á†«á„€á…¨ á„‰á…µá„‰á…³á„á…¦á†· á„€á…©á„ƒá…©á„’á…ª á„‹á…­á†¼.pdf']\n",
      "ğŸ“Š CSVì— ì íŒ PDF ëª©ë¡ (ì¼ë¶€): ['ê³ ë ¤ëŒ€í•™êµ_ì°¨ì„¸ëŒ€ í¬í„¸Â·í•™ì‚¬ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì‚¬ì—….pdf', 'ì„œìš¸ì‹œë¦½ëŒ€í•™êµ_[ì‚¬ì „ê³µê°œ] í•™ì—…ì„±ì·¨ë„ ë‹¤ì°¨ì› ì¢…ë‹¨ë¶„ì„ í†µí•©ì‹œìŠ¤í…œ 1ì°¨.pdf', 'ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf', 'ê¸°ì´ˆê³¼í•™ì—°êµ¬ì›_2025ë…„ë„ ì¤‘ì´ì˜¨ê°€ì†ê¸°ìš© ê·¹ì €ì˜¨ì‹œìŠ¤í…œ ìš´ì „ ìš©ì—­.pdf']\n",
      "\n",
      "ğŸ§ ì •ë°€ ë¹„êµ í…ŒìŠ¤íŠ¸:\n",
      "ì‹¤ì œíŒŒì¼: 'á„€á…©á„…á…§á„ƒá…¢á„’á…¡á†¨á„€á…­_á„á…¡á„‰á…¦á„ƒá…¢ á„‘á…©á„á…¥á†¯Â·á„’á…¡á†¨á„‰á…¡ á„Œá…¥á†¼á„‡á…©á„‰á…µá„‰á…³á„á…¦á†· á„€á…®á„á…®á†¨á„‰á…¡á„‹á…¥á†¸.pdf'\n",
      "CSVíŒŒì¼ : 'ê³ ë ¤ëŒ€í•™êµ_ì°¨ì„¸ëŒ€ í¬í„¸Â·í•™ì‚¬ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì‚¬ì—….pdf'\n",
      "ì¼ì¹˜ì—¬ë¶€: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. ì‹¤ì œ í´ë”ì— ìˆëŠ” PDF íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "pdf_files = [f for f in os.listdir(FILES_DIR) if f.lower().endswith('.pdf')]\n",
    "print(f\"ğŸ“ ì„œë²„ì— ìˆëŠ” ì‹¤ì œ PDF (4ê°œ): {pdf_files}\")\n",
    "\n",
    "# 2. CSVì—ì„œ PDFë¼ê³  ì£¼ì¥í•˜ëŠ” íŒŒì¼ëª…ë“¤ ì¶œë ¥\n",
    "df_meta = pd.read_csv(META_PATH)\n",
    "csv_pdf_list = [f for f in df_meta['íŒŒì¼ëª…'].tolist() if str(f).lower().endswith('.pdf')]\n",
    "print(f\"ğŸ“Š CSVì— ì íŒ PDF ëª©ë¡ (ì¼ë¶€): {csv_pdf_list[:5]}\")\n",
    "\n",
    "# 3. ì™œ ì•ˆ ë§ëŠ”ì§€ í•˜ë‚˜ë§Œ ì •ë°€ ë¹„êµ\n",
    "if pdf_files and csv_pdf_list:\n",
    "    print(\"\\nğŸ§ ì •ë°€ ë¹„êµ í…ŒìŠ¤íŠ¸:\")\n",
    "    print(f\"ì‹¤ì œíŒŒì¼: '{pdf_files[0]}'\")\n",
    "    print(f\"CSVíŒŒì¼ : '{csv_pdf_list[0]}'\")\n",
    "    print(f\"ì¼ì¹˜ì—¬ë¶€: {pdf_files[0] == csv_pdf_list[0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2182ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 14829.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(df_meta.iterrows(), total=len(df_meta)):\n",
    "    csv_f_name = str(row['íŒŒì¼ëª…']).strip().lower() # ì†Œë¬¸ìë¡œ í†µì¼ ë° ê³µë°± ì œê±°\n",
    "    \n",
    "    # ì‹¤ì œ í´ë”ì˜ íŒŒì¼ë“¤ ì¤‘ CSV íŒŒì¼ëª…ì„ í¬í•¨í•˜ëŠ” ê²ƒì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "    matched_file = None\n",
    "    for real_f in pdf_files:\n",
    "        if csv_f_name in real_f.lower() or real_f.lower() in csv_f_name:\n",
    "            matched_file = real_f\n",
    "            break\n",
    "            \n",
    "    if matched_file:\n",
    "        f_path = os.path.join(FILES_DIR, matched_file)\n",
    "        # (ì´í›„ pdfplumber ë¡œì§ ë™ì¼...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee0d472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì •ê·œí™” ì™„ë£Œëœ PDF ëª©ë¡: ['ê³ ë ¤ëŒ€í•™êµ_ì°¨ì„¸ëŒ€ í¬í„¸Â·í•™ì‚¬ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì‚¬ì—….pdf', 'ê¸°ì´ˆê³¼í•™ì—°êµ¬ì›_2025ë…„ë„ ì¤‘ì´ì˜¨ê°€ì†ê¸°ìš© ê·¹ì €ì˜¨ì‹œìŠ¤í…œ ìš´ì „ ìš©ì—­.pdf', 'ì„œìš¸ì‹œë¦½ëŒ€í•™êµ_[ì‚¬ì „ê³µê°œ] í•™ì—…ì„±ì·¨ë„ ë‹¤ì°¨ì› ì¢…ë‹¨ë¶„ì„ í†µí•©ì‹œìŠ¤í…œ 1ì°¨.pdf', 'ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:17<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë“œë””ì–´ ì„±ê³µ! 4ê±´ì˜ PDFê°€ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ë•Œ 'NFC'ë¡œ í†µì¼í•´ì„œ ì½ê¸°\n",
    "raw_files = os.listdir(FILES_DIR)\n",
    "pdf_files = [unicodedata.normalize('NFC', f) for f in raw_files if f.lower().endswith('.pdf')]\n",
    "print(f\"âœ… ì •ê·œí™” ì™„ë£Œëœ PDF ëª©ë¡: {pdf_files}\")\n",
    "\n",
    "# 2. ë§¤ì¹­ ë¡œì§ì—ë„ ì •ê·œí™” ì ìš©\n",
    "results = []\n",
    "for index, row in tqdm(df_meta.iterrows(), total=len(df_meta)):\n",
    "    # CSVì˜ íŒŒì¼ëª…ë„ NFCë¡œ ì •ê·œí™”\n",
    "    csv_f_name = unicodedata.normalize('NFC', str(row['íŒŒì¼ëª…']).strip())\n",
    "    \n",
    "    if csv_f_name in pdf_files:\n",
    "        # ì‹¤ì œ ì„œë²„ íŒŒì¼ ì‹œìŠ¤í…œì— ì ‘ê·¼í•  ë•ŒëŠ” ì›ë˜ì˜ ì´ë¦„ì„ ì°¾ì•„ì•¼ í•˜ë¯€ë¡œ ë§¤ì¹­ ìˆ˜í–‰\n",
    "        target_file = None\n",
    "        for original_f in raw_files:\n",
    "            if unicodedata.normalize('NFC', original_f) == csv_f_name:\n",
    "                target_file = original_f\n",
    "                break\n",
    "        \n",
    "        if target_file:\n",
    "            f_path = os.path.join(FILES_DIR, target_file)\n",
    "            try:\n",
    "                with pdfplumber.open(f_path) as pdf:\n",
    "                    text = \" \".join([p.extract_text() for p in pdf.pages if p.extract_text()])\n",
    "                    results.append({\n",
    "                        \"ì‚¬ì—…ëª…\": row.get('ì‚¬ì—…ëª…', 'N/A'),\n",
    "                        \"ë³¸ë¬¸\": text,\n",
    "                        \"íŒŒì¼ëª…\": csv_f_name\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {csv_f_name} ì—ëŸ¬: {e}\")\n",
    "\n",
    "# 3. ê²°ê³¼ ì €ì¥\n",
    "output_path = \"/home/spai0630/workspace/data/processed_pdf_only.jsonl\"\n",
    "pd.DataFrame(results).to_json(output_path, orient='records', force_ascii=False, lines=True)\n",
    "print(f\"ğŸš€ ë“œë””ì–´ ì„±ê³µ! {len(results)}ê±´ì˜ PDFê°€ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647f11e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ 656ê°œì˜ ì˜ë¯¸ ë‹¨ìœ„(Chunk)ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ\n",
    "input_path = \"/home/spai0630/workspace/data/processed_pdf_only.jsonl\"\n",
    "chunks = []\n",
    "chunk_size = 800  # 800ì ë‹¨ìœ„ë¡œ ìë¥´ê¸°\n",
    "chunk_overlap = 100 # ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ 100ìì”© ê²¹ì¹¨\n",
    "\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        text = data['ë³¸ë¬¸']\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ë¥¼ ì¼ì • ê¸¸ì´ë¡œ ë¶„í• \n",
    "        for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "            chunk_text = text[i:i + chunk_size]\n",
    "            chunks.append({\n",
    "                \"ì‚¬ì—…ëª…\": data['ì‚¬ì—…ëª…'],\n",
    "                \"content\": chunk_text,\n",
    "                \"metadata\": {\n",
    "                    \"source\": data['íŒŒì¼ëª…'],\n",
    "                    \"chunk_id\": i // (chunk_size - chunk_overlap)\n",
    "                }\n",
    "            })\n",
    "\n",
    "# 2. ì²­í‚¹ ê²°ê³¼ ì €ì¥\n",
    "chunk_path = \"/home/spai0630/workspace/data/chunks.jsonl\"\n",
    "with open(chunk_path, 'w', encoding='utf-8') as f:\n",
    "    for chunk in chunks:\n",
    "        f.write(json.dumps(chunk, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… ì´ {len(chunks)}ê°œì˜ ì˜ë¯¸ ë‹¨ìœ„(Chunk)ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc29ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 4ê°œ ë¬¸ì„œì—ì„œ ì´ 1021ê°œì˜ ì²­í¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "input_file = \"/home/spai0630/workspace/data/processed_pdf_only.jsonl\"\n",
    "output_file = \"/home/spai0630/workspace/data/final_chunks.jsonl\"\n",
    "\n",
    "chunks = []\n",
    "# RFP ë¬¸ì„œëŠ” ë³´í†µ ì¡°í•­ì´ ê¸¸ê¸° ë•Œë¬¸ì— 500ì ë‹¨ìœ„ê°€ ì ë‹¹í•©ë‹ˆë‹¤.\n",
    "CHUNK_SIZE = 500 \n",
    "OVERLAP = 50\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            text = item['ë³¸ë¬¸']\n",
    "            # ì²­í‚¹ ë¡œì§\n",
    "            for i in range(0, len(text), CHUNK_SIZE - OVERLAP):\n",
    "                chunk = text[i:i + CHUNK_SIZE]\n",
    "                chunks.append({\n",
    "                    \"content\": chunk,\n",
    "                    \"metadata\": {\"source\": item['íŒŒì¼ëª…'], \"title\": item['ì‚¬ì—…ëª…']}\n",
    "                })\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for c in chunks:\n",
    "            f.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "    print(f\"âœ… 4ê°œ ë¬¸ì„œì—ì„œ ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âŒ ì „ì²˜ë¦¬ëœ JSONL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c453ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ì „ì²´ ì²­í¬ ìˆ˜: 1021ê°œ\n",
      "--------------------------------------------------\n",
      "âœ¨ ìƒ˜í”Œ 1\n",
      "ğŸ“‚ ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "ğŸ“Œ ì‚¬ì—…ëª…: 2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©ì—­\n",
      "ğŸ“ ë‚´ìš© ìš”ì•½ (ì• 200ì): \n",
      " ë“±ì„ ë°˜ì… ë° ë°˜ì¶œ ì‹œ ë°œì£¼ê¸°ê´€ì˜ ìŠ¹ì¸ì„ ë°›ì•„ì•¼ í•˜ë©°, í•´ë‹¹ ê°€. ì‚¬ì—… ìˆ˜í–‰ì„ ìœ„í•´ ë°œì£¼ê¸°ê´€ì—ì„œ ìš©ì—­ì—…ì²´ì—ê²Œ ì œê³µí•˜ëŠ” ë‚´ë¶€ ìë£ŒëŠ” ìë£Œê´€ë¦¬ ëŒ€ì¥ì„\n",
      "ì¥ë¹„ì— ìœ ë£Œ ìµœì‹  ë°±ì‹ ì„ ì„¤ì¹˜í•˜ê³  ì•…ì„±ì½”ë“œë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ê²€ì‚¬í•´ì•¼ í•œë‹¤. ì‘ì„±í•˜ê³ , ì¸ê³„ìâ€¤ì¸ìˆ˜ìê°€ ìí•„ë¡œ ì„œëª…í•´ì•¼ í•œë‹¤.\n",
      "ë‹¤. ë°œì£¼ê¸°ê´€ì€ ìš©ì—­ì—…ì²´ì—ê²Œ ì œê³µí•œ ì‚¬ë¬´ì‹¤ì— ëŒ€í•´ ìˆ˜ì‹œë¡œ ë³´ì•ˆì ê²€ì„ í•  ìˆ˜ ìˆë‹¤. ë‚˜. ...\n",
      "ğŸ“ ì‹¤ì œ ê¸¸ì´: 500ì\n",
      "--------------------------------------------------\n",
      "âœ¨ ìƒ˜í”Œ 2\n",
      "ğŸ“‚ ì¶œì²˜: ê³ ë ¤ëŒ€í•™êµ_ì°¨ì„¸ëŒ€ í¬í„¸Â·í•™ì‚¬ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì‚¬ì—….pdf\n",
      "ğŸ“Œ ì‚¬ì—…ëª…: ì°¨ì„¸ëŒ€ í¬í„¸Â·í•™ì‚¬ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì‚¬ì—… \n",
      "ğŸ“ ë‚´ìš© ìš”ì•½ (ì• 200ì): \n",
      "\n",
      "ì‚¬ ì—… ëª… ì‚¬ ì—… ê¸° ê°„ ê³„ ì•½ ê¸ˆ ì•¡ ë°œ ì£¼ ì²˜ ë¹„ ê³ \n",
      "â€» ì—°ë„ìˆœìœ¼ë¡œ ê¸°ì¬í•˜ë©°, ì œì•ˆê³¼ì œì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ë™ì¼í•œ ì—…ë¬´ì˜ì—­ì´ë‚˜ ì‚¬ì—…í˜•íƒœì— ê´€í•œ\n",
      "ê²ƒë§Œ ê¸°ì¬í•œë‹¤. ë‹¨, í˜„ì¬ìˆ˜í–‰ì¤‘ì¸ ì‚¬ì—…ì€ ë¹„ê³ ë€ì— í˜„ì¬ìˆ˜í–‰ì¤‘ì„ì„ ëª…ì‹œí•œë‹¤.\n",
      "â€» í•˜ë„ê¸‰ì€ ë°œì£¼ì²˜ê°€ ìŠ¹ì¸í•œ ê²½ìš°ì— í•œí•˜ì—¬ ì‘ì„±í•˜ë©° ë¹„ê³ ë€ì— ì›ë„ê¸‰íšŒì‚¬ë¥¼ ê¸°ì¬í•œë‹¤.\n",
      "â€» ê³µë™ë„ê¸‰ê³„ì•½ì¼ ê²½ìš°ì—ëŠ” ê³„ì•½ê¸ˆì•¡ë€ì— ì œì•ˆì‚¬ì˜ ì§€ë¶„ë§Œì„ ...\n",
      "ğŸ“ ì‹¤ì œ ê¸¸ì´: 500ì\n",
      "--------------------------------------------------\n",
      "âœ¨ ìƒ˜í”Œ 3\n",
      "ğŸ“‚ ì¶œì²˜: ê¸°ì´ˆê³¼í•™ì—°êµ¬ì›_2025ë…„ë„ ì¤‘ì´ì˜¨ê°€ì†ê¸°ìš© ê·¹ì €ì˜¨ì‹œìŠ¤í…œ ìš´ì „ ìš©ì—­.pdf\n",
      "ğŸ“Œ ì‚¬ì—…ëª…: 2025ë…„ë„ ì¤‘ì´ì˜¨ê°€ì†ê¸°ìš© ê·¹ì €ì˜¨ì‹œìŠ¤í…œ ìš´ì „ ìš©ì—­\n",
      "ğŸ“ ë‚´ìš© ìš”ì•½ (ì• 200ì): \n",
      "ì˜ë  ìˆ˜ ìˆë„ë¡,\n",
      "ì¤‘ì´ì˜¨ê°€ì†ê¸°ìš© ê·¹ì €ì˜¨ì‹œìŠ¤í…œ i) ê·¹ì €ì˜¨ì‹œìŠ¤í…œì„ ëª¨ë‹ˆí„°ë§ ë° ì œì–´í•˜ê³ ,\n",
      "ìš´ì „ ì—…ë¬´ ii) ê·¹ì €ì˜¨ì‹œìŠ¤í…œì˜ ì£¼ìš” ìˆ˜ì¹˜ë¥¼ ê¸°ë¡ ë° ë¶„ì„í•˜ë©°,\n",
      "iii) ì¤‘ì´ì˜¨ê°€ì†ê¸°ìš© ê·¹ì €ì˜¨ì‹œìŠ¤í…œì˜ ìš´ì „ ê²½í—˜ì„\n",
      "í†µí•©í•˜ì—¬ ì •ë¦¬(ë¬¸ì„œí™”)í•˜ëŠ” ì—…ë¬´ ë¬¸ì„œë²ˆí˜¸ : -\n",
      "2025ë…„ë„ ì¤‘ì´ì˜¨ê°€ì†ê¸°ìš© ê·¹ì €ì˜¨ì‹œìŠ¤í…œ\n",
      "ê°œì •ë²ˆí˜¸ : 0\n",
      "ìš´ì „ ìš©ì—­ ê³¼ì—…ì§€ì‹œì„œ ë°œ í–‰ ì¼ : 2024. 10....\n",
      "ğŸ“ ì‹¤ì œ ê¸¸ì´: 500ì\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "chunk_path = \"/home/spai0630/workspace/data/final_chunks.jsonl\"\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "with open(chunk_path, 'r', encoding='utf-8') as f:\n",
    "    all_chunks = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"ğŸ“¦ ì „ì²´ ì²­í¬ ìˆ˜: {len(all_chunks)}ê°œ\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ëœë¤í•˜ê²Œ 3ê°œ ì¶”ì¶œí•´ì„œ í™•ì¸\n",
    "sample_chunks = random.sample(all_chunks, 3)\n",
    "\n",
    "for i, chunk in enumerate(sample_chunks):\n",
    "    print(f\"âœ¨ ìƒ˜í”Œ {i+1}\")\n",
    "    print(f\"ğŸ“‚ ì¶œì²˜: {chunk['metadata']['source']}\")\n",
    "    print(f\"ğŸ“Œ ì‚¬ì—…ëª…: {chunk['metadata']['title']}\")\n",
    "    print(f\"ğŸ“ ë‚´ìš© ìš”ì•½ (ì• 200ì): \\n{chunk['content'][:200]}...\")\n",
    "    print(f\"ğŸ“ ì‹¤ì œ ê¸¸ì´: {len(chunk['content'])}ì\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de3529",
   "metadata": {},
   "source": [
    "ê¸€ììˆ˜ ê¸°ë°˜ ì²­í‚¹ ê²°ê³¼ê°€ ì œë²• ì¢‹ë‹¤. \n",
    "ê¸€ì ê¹¨ì§ë„ ì—†ê³  ì¶œì²˜ì™€ ì‚¬ì—…ëª… ë©”íƒ€ ë°ì´í„° ì—­ì‹œë„ ì •í™•í•˜ê²Œ ë‚˜ì˜¤ê³  ìˆë‹¤.\n",
    "í•˜ì§€ë§Œ ê·¸ë˜ë„ ì¤‘ê°„ì— ë¬¸ì¥ì´ ëŠê¸°ëŠ” í˜„ìƒì´ ë°œìƒí•˜ê³  ìˆì–´ì„œ \n",
    "ì˜ë¯¸ë¡ ì  ì²­í‚¹ì„ ì‹œë„í•´ë³´ê³  ì‹¶ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "298dcbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langchain_experimental) (1.2.8)\n",
      "Requirement already satisfied: langchain-community<1.0.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.0.46)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.6.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in ./venv/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_experimental) (26.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_experimental) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_experimental) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.1.0)\n",
      "Downloading langchain_experimental-0.4.1-py3-none-any.whl (210 kB)\n",
      "Installing collected packages: langchain_experimental\n",
      "Successfully installed langchain_experimental-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d940e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: langchain-experimental in ./venv/lib/python3.12/site-packages (0.4.1)\n",
      "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-5.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.3.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from sentence-transformers) (2.4.2)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.2)\n",
      "Collecting filelock (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.1.15)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typer-slim (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Collecting shellingham (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langchain-experimental) (1.2.8)\n",
      "Requirement already satisfied: langchain-community<1.0.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.0.46)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.32.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.6.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in ./venv/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting cuda-bindings==12.9.4 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.6.0 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting cuda-pathfinder~=1.1 (from cuda-bindings==12.9.4->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading cuda_pathfinder-1.3.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading sentence_transformers-5.2.2-py3-none-any.whl (494 kB)\n",
      "Downloading transformers-5.0.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-1.3.7-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m  \u001b[33m0:00:52\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:30\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m  \u001b[33m0:00:36\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m  \u001b[33m0:00:17\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m  \u001b[33m0:00:17\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cuda_pathfinder-1.3.3-py3-none-any.whl (27 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, threadpoolctl, sympy, shellingham, setuptools, scipy, safetensors, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, joblib, hf-xet, fsspec, filelock, cuda-pathfinder, click, typer-slim, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, cuda-bindings, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40/40\u001b[0m [sentence-transformers]sformers]ub]cu12]2]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 click-8.3.1 cuda-bindings-12.9.4 cuda-pathfinder-1.3.3 filelock-3.20.3 fsspec-2026.1.0 hf-xet-1.2.0 huggingface-hub-1.3.7 jinja2-3.1.6 joblib-1.5.3 mpmath-1.3.0 networkx-3.6.1 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.17.0 sentence-transformers-5.2.2 setuptools-80.10.2 shellingham-1.5.4 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.2 torch-2.10.0 transformers-5.0.0 triton-3.6.0 typer-slim-0.21.1\n"
     ]
    }
   ],
   "source": [
    "# ì˜ë¯¸ ë¶„ì„ ì—”ì§„ê³¼ ì‹¤í—˜ì  ê¸°ëŠ¥ íŒ¨í‚¤ì§€ë¥¼ í•¨ê»˜ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "!pip install sentence-transformers langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d9db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d7776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  ì˜ë¯¸ ë¶„ì„ì„ ìœ„í•œ ëª¨ë¸ ë¡œë“œ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spai0630/workspace/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 641.23it/s, Materializing param=pooler.dense.weight]                               \n",
      "RobertaModel LOAD REPORT from: jhgan/ko-sroberta-multitask\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ ì˜ë¯¸ë¡ ì  ì²­í‚¹ ì‹œì‘ (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)...\n",
      "âœ… ì˜ë¯¸ë¡ ì  ì²­í‚¹ ì™„ë£Œ! ìƒì„±ëœ ì²­í¬ ìˆ˜: 141ê°œ\n",
      "\n",
      "ğŸ“ ì˜ë¯¸ë¡ ì  ì²­í¬ ìƒ˜í”Œ:\n",
      "ì œ ì•ˆ ìš” ì²­ ì„œ\n",
      "ê³ ë ¤ëŒ€í•™êµ\n",
      "ì°¨ì„¸ëŒ€ í¬í„¸Â·í•™ì‚¬ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶• ì‚¬ì—…\n",
      "2024. 7. 01\n",
      "â€» ë³¸ ìë£ŒëŠ” ì œì•ˆë‚´ìš©ì˜ ì„¤ëª…ì„ ìœ„í•œ ë°°í¬ìë£Œë¡œ, ì´ì™¸ ëª©ì ìœ¼ë¡œ ë¬´ë‹¨ë³µì œ, ì „ë‹¬ ë° ì‚¬ìš©í•˜ëŠ” í–‰ìœ„ë¥¼ ê¸ˆí•¨. -1- ëª© ì°¨\n",
      "â… . ì‚¬ì—…ê°œìš” Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· 4\n",
      "1. ì‚¬ì—… ê°œìš” Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install langchain-experimental\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import json\n",
    "\n",
    "# 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì˜ë¯¸ ë¶„ì„ì„ ìœ„í•´ í•„ìš”)\n",
    "print(\"ğŸ§  ì˜ë¯¸ ë¶„ì„ì„ ìœ„í•œ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# 2. ì˜ë¯¸ë¡ ì  ì²­ì»¤ ì„¤ì •\n",
    "# breakpoint_threshold_typeì€ ë¬¸ì¥ ê°„ì˜ ì°¨ì´ë¥¼ ì–´ë–»ê²Œ ê³„ì‚°í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings, \n",
    "    breakpoint_threshold_type=\"percentile\" # í•˜ìœ„ %ì˜ ìœ ì‚¬ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• \n",
    ")\n",
    "\n",
    "# 3. ì›ë³¸ ë°ì´í„° ë¡œë“œ (JSONLì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ)\n",
    "input_path = \"/home/spai0630/workspace/data/processed_pdf_only.jsonl\"\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    raw_data = [json.loads(line) for line in f]\n",
    "\n",
    "semantic_chunks = []\n",
    "print(\"âœ‚ï¸ ì˜ë¯¸ë¡ ì  ì²­í‚¹ ì‹œì‘ (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)...\")\n",
    "\n",
    "for item in raw_data:\n",
    "    docs = text_splitter.create_documents([item['ë³¸ë¬¸']])\n",
    "    for i, doc in enumerate(docs):\n",
    "        semantic_chunks.append({\n",
    "            \"content\": doc.page_content,\n",
    "            \"metadata\": {\n",
    "                \"source\": item['íŒŒì¼ëª…'],\n",
    "                \"title\": item['ì‚¬ì—…ëª…'],\n",
    "                \"chunk_id\": i,\n",
    "                \"type\": \"semantic\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "print(f\"âœ… ì˜ë¯¸ë¡ ì  ì²­í‚¹ ì™„ë£Œ! ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(semantic_chunks)}ê°œ\")\n",
    "\n",
    "# ìƒ˜í”Œ í™•ì¸ (ì²« ë²ˆì§¸ ê²ƒë§Œ)\n",
    "if semantic_chunks:\n",
    "    print(\"\\nğŸ“ ì˜ë¯¸ë¡ ì  ì²­í¬ ìƒ˜í”Œ:\")\n",
    "    print(semantic_chunks[0]['content'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86a565",
   "metadata": {},
   "source": [
    "ê¸¸ì´ ê¸°ë°˜ ì²­í‚¹ì—ì„œëŠ” 1021ê°œ ì˜€ë˜ ì²­í¬ê°€ ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹í•˜ë‹ˆê¹Œ 141ê°œë¡œ ëŒ€í­ ì¤„ì—ˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ê¸¸ì´ ê¸°ë°˜ ì²˜ëŸ¼ ë‚´ìš©ì´ ì¤‘ê°„ì— ë§¥ë½ì—†ì´ ì˜ë¦¬ëŠ” í˜„ìƒ ì—­ì‹œ ì‚¬ë¼ì ¸ í›¨ì”¬ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ì„ ë§Œë“¤ì–´ë‚¼ ê°€ëŠ¥ì„±ì´ ë†’ì•„ ë³´ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1fee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
