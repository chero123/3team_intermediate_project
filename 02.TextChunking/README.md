# RAG ì²­í‚¹ ì „ëµ í‰ê°€ í”„ë¡œì íŠ¸

> 5ê°€ì§€ ì²­í‚¹ ë°©ì‹ Ã— 3ê°€ì§€ ì„ë² ë”© ëª¨ë¸ = 15ê°œ ì¡°í•© ë²¤ì¹˜ë§ˆí¬

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![CUDA](https://img.shields.io/badge/CUDA-GTX%201660%20SUPER-green.svg)](https://developer.nvidia.com/cuda-zone)

---

## ëª©ì°¨
- [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
- [í‰ê°€ ê²°ê³¼ ìš”ì•½](#í‰ê°€-ê²°ê³¼-ìš”ì•½)
- [íŒ€ì›ë³„ ì²­í‚¹ ë°©ì‹](#íŒ€ì›ë³„-ì²­í‚¹-ë°©ì‹)
- [ì„±ëŠ¥ ë¹„êµ ìƒì„¸](#ì„±ëŠ¥-ë¹„êµ-ìƒì„¸)
- [í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ](#í…ŒìŠ¤íŠ¸-ê°€ì´ë“œ)
- [ê¶Œì¥ì‚¬í•­](#ê¶Œì¥ì‚¬í•­)

---

## í”„ë¡œì íŠ¸ ê°œìš”

RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì—ì„œ **ì²­í‚¹(Chunking)**ê³¼ **ì„ë² ë”© ëª¨ë¸** ì„ íƒì€ ê²€ìƒ‰ í’ˆì§ˆì„ ê²°ì •í•˜ëŠ” í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤. ë³¸ í”„ë¡œì íŠ¸ëŠ” 3íŒ€ íŒ€ì›ë“¤ì´ ê°œë°œí•œ 5ê°€ì§€ ì²­í‚¹ ì „ëµê³¼ 3ê°€ì§€ ì„ë² ë”© ëª¨ë¸ì„ ì¡°í•©í•˜ì—¬ ì‹¤ì œ ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.

### í‰ê°€ í™˜ê²½
- **í‰ê°€ ë°ì´í„°ì…‹**: 2ê°œ (ê° 40ê°œ ì§ˆë¬¸)
- **ì²­í‚¹ ë°©ì‹**: 5ê°€ì§€ (Recursive, Paragraph, Semantic, ContextEnriched, Hierarchical)
- **ì„ë² ë”© ëª¨ë¸**: 3ê°€ì§€ (MiniLM, ko-sroberta, OpenAI text-embedding-3-small)
- **ì´ ì¡°í•©**: 15ê°€ì§€
- **GPU**: NVIDIA GeForce GTX 1660 SUPER
- **Vector DB**: FAISS, ChromaDB

---

## í‰ê°€ ê²°ê³¼ ìš”ì•½

### ìµœê³  ì„±ëŠ¥ ì¡°í•©

| ìˆœìœ„ | ì²­í‚¹ ë°©ì‹ | ì„ë² ë”© ëª¨ë¸ | Dataset 1 | Dataset 2 | í‰ê·  Hit@1 | Latency |
|------|-----------|-------------|-----------|-----------|------------|---------|
| 1 | **ê¹€íŒ€ì›-ContextEnriched** | **OpenAI** | 90.00% | 85.00% | **87.50%** | 318.8ms |
| 2 | ì•ˆíŒ€ì›-Recursive | ko-sroberta | 90.00% | 65.00% | 77.50% | 69.2ms |
| 3 | ê¹€íŒ€ì›-ContextEnriched | ko-sroberta | 87.50% | 77.50% | 82.50% | 59.7ms |
| 4 | ì„œíŒ€ì›-Semantic | ko-sroberta | 87.50% | 60.00% | 73.75% | 54.1ms |
| 5 | ì¥íŒ€ì›-Hierarchical | ko-sroberta | 82.50% | 57.50% | 70.00% | 72.4ms |

### ì£¼ìš” ë°œê²¬ì‚¬í•­

#### 1. ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥
- **ko-sroberta**: ê°€ì¥ ì•ˆì •ì ì´ê³  ê· í˜•ì¡íŒ ì„±ëŠ¥ (í‰ê·  66.8%)
  - Dataset 1: í‰ê·  70.5%
  - Dataset 2: í‰ê·  63.0%
- **OpenAI**: ìµœê³  ì •í™•ë„ì´ì§€ë§Œ ë°ì´í„°ì…‹ ê°„ í¸ì°¨ ì¡´ì¬ (í‰ê·  66.5%)
  - Dataset 1: í‰ê·  73.0%
  - Dataset 2: í‰ê·  60.0%
- **MiniLM**: í•œêµ­ì–´ ë„ë©”ì¸ì—ì„œ í˜„ì €íˆ ë‚®ì€ ì„±ëŠ¥ (í‰ê·  12.5%)
  - Dataset 1: í‰ê·  21.0%
  - Dataset 2: í‰ê·  4.0%

#### 2. ì²­í‚¹ ë°©ì‹ íš¨ê³¼
- **ContextEnriched (ê¹€íŒ€ì›)**: ë‘ ë°ì´í„°ì…‹ ëª¨ë‘ ìµœìƒìœ„ (í‰ê·  77.5%)
  - ë©”íƒ€ë°ì´í„° ì£¼ì…ìœ¼ë¡œ ì²­í¬ ë¶„ë¦¬ í›„ì—ë„ ë¬¸ë§¥ ìœ ì§€
- **Recursive (ì•ˆíŒ€ì›)**: Dataset 1ì—ì„œ ìš°ìˆ˜ (90%), Dataset 2ì—ì„œ ì¤‘ê°„ (65%)
- **Paragraph (ë°•íŒ€ì›)**: ì²­í¬ ìˆ˜ê°€ ë§ì§€ë§Œ (11,764ê°œ) ì„±ëŠ¥ì€ ë‚®ìŒ
  - Dataset 1: í‰ê·  29.2%
  - Dataset 2: í‰ê·  35.8%

#### 3. ì†ë„ vs ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„

| ì¡°í•© | Hit@1 | Latency | íŠ¹ì§• |
|------|-------|---------|------|
| ê¹€íŒ€ì›-ContextEnriched + OpenAI | 87.50% | 318.8ms | ìµœê³  ì •í™•ë„ |
| ê¹€íŒ€ì›-ContextEnriched + ko-sroberta | 82.50% | 59.7ms | **ê· í˜•ì ** |
| ì„œíŒ€ì›-Semantic + ko-sroberta | 73.75% | 54.1ms | ìµœê³  ì†ë„ |

---

## íŒ€ì›ë³„ ì²­í‚¹ ë°©ì‹

### ì•ˆíŒ€ì› - RecursiveCharacterTextSplitter

**íŠ¹ì§•**: LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©, ì¬ê·€ì  ë¶„í• 

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=chunk_size,
    chunk_overlap=overlap,
    separators=["\n\n", "\n", "â–¡", "ã€‚", ".", "!", "?", " ", ""],
)
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ë¶„í•  ìš°ì„ ìˆœìœ„ | ë¬¸ë‹¨(`\n\n`) â†’ ì¤„(`\n`) â†’ ê³µê³ ë¬¸ ê¸°í˜¸(`â–¡`) â†’ ë¬¸ì¥ë¶€í˜¸ â†’ ê³µë°± |
| ì²­í¬ í¬ê¸° | ì™¸ë¶€ íŒŒë¼ë¯¸í„°ë¡œ ì£¼ì… |
| HWP íŒŒì‹± | `hwp5txt` CLI |
| ì„ë² ë”© ëª¨ë¸ | `dragonkue/BGE-m3-ko` |
| Vector DB | FAISS |
| ê²°ê³¼ ì²­í¬ ìˆ˜ | 9,625ê°œ |

**í‰ê°€ ê²°ê³¼** (ko-sroberta ê¸°ì¤€)
- Dataset 1: Hit@1 90.00%, MRR 0.9125
- Dataset 2: Hit@1 65.00%, MRR 0.7042

---

### ë°•íŒ€ì› - ì»¤ìŠ¤í…€ ë¬¸ë‹¨ ê¸°ë°˜ ì²­í‚¹

**íŠ¹ì§•**: ì™¸ë¶€ ì˜ì¡´ì„± ì—†ëŠ” ì ì‘í˜• ì²­í‚¹

```python
def paragraph_chunking(
    text: str,
    min_chars: int = 200,
    max_chars: int = 800,
    overlap: int = 100
):
    # 1. ë¹ˆ ì¤„ ê¸°ì¤€ ë¬¸ë‹¨ ë¶„ë¦¬
    paragraphs = [p.strip() for p in text.split("\n\n") if p.strip()]
    
    # 2. ì§§ì€ ë¬¸ë‹¨ í•©ì¹˜ê¸°, ê¸´ ë¬¸ë‹¨ ë¶„ë¦¬
    # 3. overlap ì ìš©
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ë¶„í•  ê¸°ì¤€ | ë¹ˆ ì¤„(`\n\n`) ê¸°ì¤€ ë¬¸ë‹¨ |
| ì²­í¬ í¬ê¸° | 200~800ì (ê°€ë³€) |
| HWP íŒŒì‹± | `olefile` + `zlib` ì§ì ‘ êµ¬í˜„ |
| ì„ë² ë”© ëª¨ë¸ | `all-MiniLM-L6-v2` |
| Vector DB | FAISS |
| ê²°ê³¼ ì²­í¬ ìˆ˜ | 11,764ê°œ |

**í‰ê°€ ê²°ê³¼** (OpenAI ê¸°ì¤€)
- Dataset 1: Hit@1 80.00%, MRR 0.8708
- Dataset 2: Hit@1 52.50%, MRR 0.5725

---

### ì„œíŒ€ì› - ì˜ë¯¸ë¡ ì  ì²­í‚¹ (SemanticChunker)

**íŠ¹ì§•**: ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ë¶„ì„, ë¬¸ì¥ ì¤‘ê°„ ëŠê¹€ ì—†ìŒ

```python
from langchain_experimental.text_splitter import SemanticChunker

embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

text_splitter = SemanticChunker(
    embeddings,
    breakpoint_threshold_type="percentile"
)
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ë¶„í•  ê¸°ì¤€ | ë¬¸ì¥ ê°„ ì˜ë¯¸ ìœ ì‚¬ë„ |
| ì²­í¬ í¬ê¸° | ê°€ë³€ (ì˜ë¯¸ ë‹¨ìœ„) |
| Overlap | ì—†ìŒ (ì˜ë¯¸ ê²½ê³„ì—ì„œ ë¶„í• ) |
| ì„ë² ë”© ëª¨ë¸ | `jhgan/ko-sroberta-multitask` |
| ê²°ê³¼ ì²­í¬ ìˆ˜ | 8,622ê°œ |

**í‰ê°€ ê²°ê³¼** (ko-sroberta ê¸°ì¤€)
- Dataset 1: Hit@1 87.50%, MRR 0.8875
- Dataset 2: Hit@1 60.00%, MRR 0.6729

---

### ê¹€íŒ€ì› - Context Enrichment + ì²­í‚¹ â­

**íŠ¹ì§•**: ë©”íƒ€ë°ì´í„° ì£¼ì…ìœ¼ë¡œ ë¬¸ë§¥ ë³´ì¡´

```python
# Context Enrichment
enriched_content = f"""[[ì‚¬ì—… ê°œìš”]]
ì‚¬ì—…ëª…: {metadata['title']}
ë°œì£¼ê¸°ê´€: {metadata['agency']}
ê³µê³ ë²ˆí˜¸: {metadata['notice_id']}

[[ë³¸ë¬¸]]
{content}"""

# RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " ", ""]
)
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ë¶„í•  ê¸°ì¤€ | ë¬¸ë‹¨ â†’ ì¤„ â†’ ë¬¸ì¥ â†’ ê³µë°± |
| ì²­í¬ í¬ê¸° | 1000ì |
| HWP íŒŒì‹± | `hwp5txt` CLI |
| PDF íŒŒì‹± | `PyMuPDF (fitz)` |
| ì„ë² ë”© ëª¨ë¸ | `text-embedding-3-small` (OpenAI) |
| Vector DB | ChromaDB |
| ê²°ê³¼ ì²­í¬ ìˆ˜ | 9,625ê°œ |

**í‰ê°€ ê²°ê³¼** (OpenAI ê¸°ì¤€)
- Dataset 1: Hit@1 **90.00%**, MRR **0.9375** ğŸ†
- Dataset 2: Hit@1 **85.00%**, MRR **0.8675** ğŸ†

---

### ì¥íŒ€ì› - ê³„ì¸µ êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹ (HierarchicalChunker)

**íŠ¹ì§•**: ê³µê³ ë¬¸ êµ¬ì¡° ì¸ì‹ (ë¡œë§ˆìˆ«ì, ê°€ë‚˜ë‹¤) + í…Œì´ë¸” ìë™ ê°ì§€

```python
class HierarchicalChunkerV2:
    def __init__(self, chunk_size=1000, overlap_ratio=0.2):
        self.hierarchy_patterns = [
            (1, re.compile(r"^[â… â…¡â…¢â…£â…¤â…¥â…¦â…§â…¨â…©]+[\.\s]")),  # Level 1
            (2, re.compile(r"^(\d+)[\.\)]\s")),              # Level 2
            (3, re.compile(r"^([ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬][\.\)]\s")),    # Level 3
        ]
        self.table_detector = TableDetector()
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ë¶„í•  ê¸°ì¤€ | ë¡œë§ˆìˆ«ì(â… ) â†’ ìˆ«ì(1.) â†’ ê°€ë‚˜ë‹¤(ê°€.) |
| ì²­í¬ í¬ê¸° | 1000ì |
| Overlap | 20% (ë¹„ìœ¨ ê¸°ë°˜) |
| í…Œì´ë¸” ê°ì§€ | íƒ­/ê³µë°± ì •ë ¬, í‚¤-ê°’ í…Œì´ë¸” |
| ì„ë² ë”© ëª¨ë¸ | `dragonkue/BGE-m3-ko` |
| Vector DB | ChromaDB |
| ê²°ê³¼ ì²­í¬ ìˆ˜ | 12,240ê°œ |

**í‰ê°€ ê²°ê³¼** (ko-sroberta ê¸°ì¤€)
- Dataset 1: Hit@1 82.50%, MRR 0.8529
- Dataset 2: Hit@1 57.50%, MRR 0.6792

---

## ì„±ëŠ¥ ë¹„êµ ìƒì„¸

### Dataset 1 ê²°ê³¼ (ì§ˆë¬¸ 40ê°œ)

| ì²­í‚¹ ë°©ì‹ | MiniLM | ko-sroberta | OpenAI | ì²­í¬ ìˆ˜ |
|----------|---------|-------------|--------|---------|
| ì•ˆíŒ€ì›-Recursive | 20.00% | **90.00%** | 65.00% | 9,625 |
| ë°•íŒ€ì›-Paragraph | 2.50% | 5.00% | **80.00%** | 11,764 |
| ì„œíŒ€ì›-Semantic | 30.00% | **87.50%** | 65.00% | 8,622 |
| ê¹€íŒ€ì›-ContextEnriched | 22.50% | 87.50% | **90.00%** | 9,625 |
| ì¥íŒ€ì›-Hierarchical | 30.00% | **82.50%** | 65.00% | 12,240 |

### Dataset 2 ê²°ê³¼ (ì§ˆë¬¸ 40ê°œ)

| ì²­í‚¹ ë°©ì‹ | MiniLM | ko-sroberta | OpenAI | ì²­í¬ ìˆ˜ |
|----------|---------|-------------|--------|---------|
| ì•ˆíŒ€ì›-Recursive | 0.00% | 65.00% | 50.00% | 9,625 |
| ë°•íŒ€ì›-Paragraph | 0.00% | 55.00% | 52.50% | 11,764 |
| ì„œíŒ€ì›-Semantic | 0.00% | 60.00% | 50.00% | 8,622 |
| ê¹€íŒ€ì›-ContextEnriched | 10.00% | 77.50% | **85.00%** | 9,625 |
| ì¥íŒ€ì›-Hierarchical | 10.00% | 57.50% | 50.00% | 12,240 |

### ì„¸ë¶€ ì§€í‘œ (Top 5)

| ì¡°í•© | Dataset | Hit@1 | Hit@5 | MRR | Latency |
|------|---------|-------|-------|-----|---------|
| ê¹€íŒ€ì›-ContextEnriched + OpenAI | 1 | 90.00% | 97.50% | 0.9375 | 314.0ms |
| ê¹€íŒ€ì›-ContextEnriched + OpenAI | 2 | 85.00% | 90.00% | 0.8675 | 323.5ms |
| ì•ˆíŒ€ì›-Recursive + ko-sroberta | 1 | 90.00% | 92.50% | 0.9125 | 77.1ms |
| ê¹€íŒ€ì›-ContextEnriched + ko-sroberta | 1 | 87.50% | 97.50% | 0.9037 | 60.7ms |
| ì„œíŒ€ì›-Semantic + ko-sroberta | 1 | 87.50% | 90.00% | 0.8875 | 54.8ms |

---

## í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### í™˜ê²½ ì„¤ì •

```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install langchain langchain-text-splitters langchain-experimental
pip install sentence-transformers faiss-cpu chromadb
pip install olefile pdfplumber pymupdf openai

# HWP íŒŒì‹±ìš© (Linux/Mac)
pip install pyhwp
```

### íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰ ìˆœì„œ

```bash
# 1ë‹¨ê³„: ì›ë³¸ íŒŒì¼ íŒŒì‹± (HWP/PDF â†’ TXT)
# team_chunking.pyì—ì„œ RUN_MODE = "parse"ë¡œ ë³€ê²½ í›„
python team_chunking.py
# ê²°ê³¼: data/parsing_data/*.txt

# 2ë‹¨ê³„: ê³„ì¸µ êµ¬ì¡° ì²­í‚¹ (TXT â†’ JSON)
# team_chunking.pyì—ì„œ RUN_MODE = "compare"ë¡œ ë³€ê²½ í›„
python team_chunking.py
# ê²°ê³¼: data/chunking_data/*.json

# 3ë‹¨ê³„: ì²­í‚¹ 5ê°€ì§€ Ã— ì„ë² ë”© 3ê°€ì§€ = 15ê°€ì§€ ì¡°í•© í…ŒìŠ¤íŠ¸
python embedding_evaluation.py
# ê²°ê³¼: evaluation_results.json
```

### ê°œë³„ ì²­í‚¹ ë°©ì‹ í…ŒìŠ¤íŠ¸

#### A. ê³ ì • ê¸¸ì´ ì²­í‚¹ (text_parsing.py)

```python
from text_parsing import process_all_files, chunk_text

# ì „ì²´ íŒŒì¼ ì²˜ë¦¬
parsed_docs = process_all_files(
    input_dir="data/original_data",
    output_dir="data/parsing_data",
    enable_chunking=True,
    chunk_size=1000,
    chunk_overlap=200,
)

# ë‹¨ì¼ íŒŒì¼ í…ŒìŠ¤íŠ¸
text = load_file_content("data/original_data/sample.hwp")
chunks = chunk_text(text, "sample", chunk_size=800, overlap=100)
print(f"ìƒì„±ëœ ì²­í¬: {len(chunks)}ê°œ")
```

#### B. ê³„ì¸µ êµ¬ì¡° ì²­í‚¹ (hierarchical_chunker_v2.py)

```python
from hierarchical_chunker_v2 import HierarchicalChunkerV2

chunker = HierarchicalChunkerV2(
    chunk_size=1000,
    overlap_ratio=0.2,
    min_chunk_size=200,
)

chunks = chunker.chunk_document(
    text=text,
    doc_id="sample",
    metadata={"source": "sample.hwp"}
)

# ê²°ê³¼ í™•ì¸
for chunk in chunks[:3]:
    print(f"ê³„ì¸µ: {chunk.metadata.get('hierarchy_path')}")
    print(f"í…Œì´ë¸”: {len(chunk.tables)}ê°œ")
```

---

## ê¶Œì¥ì‚¬í•­

### í”„ë¡œë•ì…˜ í™˜ê²½

| ì‹œë‚˜ë¦¬ì˜¤ | ì¶”ì²œ ì¡°í•© | ì´ìœ  |
|----------|-----------|------|
| **ê³ ì •ë°€ ìš”êµ¬** | ê¹€íŒ€ì›-ContextEnriched + OpenAI | ìµœê³  ì •í™•ë„ (í‰ê·  87.5%) |
| **ì†ë„ì™€ ì •í™•ë„ ê· í˜•** | ê¹€íŒ€ì›-ContextEnriched + ko-sroberta | 82.5% ì •í™•ë„, 60ms ì‘ë‹µ |
| **ë¹„ìš© ìµœì í™”** | ì„œíŒ€ì›-Semantic + ko-sroberta | 73.8% ì •í™•ë„, 54ms ì‘ë‹µ |
| **ì•ˆì •ì„± ìš°ì„ ** | ì•ˆíŒ€ì›-Recursive + ko-sroberta | ê²€ì¦ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ |

### ì²­í‚¹ íŒŒë¼ë¯¸í„° ì„¤ì •

ê³µê³µ ì…ì°° ê³µê³ (RFP) ë¬¸ì„œ ê¸°ì¤€

| ìš©ë„ | chunk_size | overlap | ë¹„ê³  |
|------|------------|---------|------|
| **ì •ë°€ ê²€ìƒ‰** | 500~800 | 100 | ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ê²€ìƒ‰ ì‹œ |
| **ì¼ë°˜ ê²€ìƒ‰** | 800~1000 | 150~200 | ë²”ìš© RAG ì‹œìŠ¤í…œ (ê¶Œì¥) |
| **ìš”ì•½/ê°œìš”** | 1500~2000 | 300 | ì „ì²´ ë¬¸ë§¥ íŒŒì•… ì‹œ |

### ê°œì„  ë°©í–¥

1. **MiniLM ì‚¬ìš© ì§€ì–‘**: í•œêµ­ì–´ íŠ¹í™” ë„ë©”ì¸ì—ì„œ í˜„ì €íˆ ë‚®ì€ ì„±ëŠ¥ (4-21%)
2. **ì²­í¬ ìˆ˜ ìµœì í™”**: ë§ë‹¤ê³  ì¢‹ì€ ê²ƒì´ ì•„ë‹˜ (Paragraph 11,764ê°œ vs ContextEnriched 9,625ê°œ)
3. **Context Enrichment ì ìš©**: ë©”íƒ€ë°ì´í„° ì£¼ì…ìœ¼ë¡œ ì²­í¬ ë¶„ë¦¬ í›„ì—ë„ ë¬¸ë§¥ ìœ ì§€
4. **OpenAI ì„ë² ë”© ê²€ì¦ í•„ìš”**: ë°ì´í„°ì…‹ ê°„ í¸ì°¨ ì¡´ì¬ (Dataset 1: 73%, Dataset 2: 60%)
5. **ko-sroberta ì¶”ì²œ**: ê°€ì¥ ì•ˆì •ì ì´ê³  ê· í˜•ì¡íŒ ì„±ëŠ¥ (í‰ê·  66.8%)

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
rag-evaluation/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ original_data/          # ì›ë³¸ HWP/PDF íŒŒì¼
â”‚   â”œâ”€â”€ parsing_data/           # íŒŒì‹±ëœ TXT íŒŒì¼
â”‚   â”œâ”€â”€ chunking_data/          # ì²­í‚¹ëœ JSON íŒŒì¼
â”‚   â”œâ”€â”€ evaluation_dataset.json # í‰ê°€ ë°ì´í„°ì…‹ 1
â”‚   â””â”€â”€ evaluation_dataset2.json# í‰ê°€ ë°ì´í„°ì…‹ 2
â”œâ”€â”€ embedding_evaluation.py      # ì „ì²´ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ team_chunking.py            # í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md
```

---

## ì¢…í•© ë¹„êµí‘œ

| í•­ëª© | ì•ˆíŒ€ì› | ë°•íŒ€ì› | ì„œíŒ€ì› | ê¹€íŒ€ì› | ì¥íŒ€ì› |
|------|--------|--------|--------|--------|--------|
| **ì²­í‚¹ ë°©ì‹** | RecursiveCharacter | ì»¤ìŠ¤í…€ ë¬¸ë‹¨ ê¸°ë°˜ | SemanticChunker | Context Enrichment | Hierarchical |
| **ë¶„í•  ê¸°ì¤€** | ë¬¸ë‹¨â†’ì¤„â†’ë¬¸ì¥ | ë¹ˆ ì¤„(`\n\n`) | ì˜ë¯¸ ìœ ì‚¬ë„ | ë¬¸ë‹¨â†’ì¤„â†’ë¬¸ì¥ | ê³„ì¸µêµ¬ì¡°(â… â†’1.â†’ê°€.) |
| **ì²­í¬ í¬ê¸°** | ì™¸ë¶€ íŒŒë¼ë¯¸í„° | 200~800ì | ê°€ë³€ | 1000ì | 1000ì |
| **Overlap** | ì™¸ë¶€ íŒŒë¼ë¯¸í„° | 100ì | ì—†ìŒ | 200ì | 20% |
| **ì²­í¬ ìˆ˜** | 9,625 | 11,764 | 8,622 | 9,625 | 12,240 |
| **Dataset 1** | 90.0% | 80.0% | 87.5% | **90.0%** | 82.5% |
| **Dataset 2** | 65.0% | 52.5% | 60.0% | **85.0%** | 57.5% |
| **í‰ê·  ì„±ëŠ¥** | 77.5% | 66.3% | 73.8% | **87.5%** | 70.0% |
| **HWP íŒŒì‹±** | `hwp5txt` | `olefile` | ì‹¤íŒ¨ | `hwp5txt` | - |
| **Vector DB** | FAISS | FAISS | - | ChromaDB | ChromaDB |
| **í…Œì´ë¸” ì²˜ë¦¬** | X | X | X | X | O |

---

## ì°¸ê³  ë¬¸í—Œ

- LangChain Text Splitters: https://python.langchain.com/docs/modules/data_connection/document_transformers/
- Semantic Chunking: https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker
- OpenAI Embeddings: https://platform.openai.com/docs/guides/embeddings

---

## ìµœì¢… ìˆ˜ì • ë‚ ì§œ
2025.02.05

## ë¼ì´ì„ ìŠ¤
MIT License

## ê¸°ì—¬ì
AI6ê¸° 3íŒ€ - ë°•íŒ€ì›, ì•ˆíŒ€ì›, ì„œíŒ€ì›, ê¹€íŒ€ì›, ì¥íŒ€ì›