import streamlit as st
from pathlib import Path
import re
import getpass
import shutil
import subprocess
import uuid
import sys
import os
import time
import glob
import fitz  # pymupdf
from dotenv import load_dotenv  #  ì¶”ê°€ env ë¡œë“œ

load_dotenv()  # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers.ensemble import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import (
    RunnablePassthrough,
    RunnableParallel,
    RunnableLambda,
)
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage

# tts ê³ ìœ  ëª¨ë“ˆ
from tts_worker import TTSWorker
from memory_store import SessionMemoryStore

# ì „ì—­ TTS ì›Œì»¤: ìƒˆ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì´ì „ ì¬ìƒì„ ì¦‰ì‹œ ì¤‘ë‹¨í•œë‹¤.
_TTS_WORKER: TTSWorker | None = None

# =========================================
# 0. í™˜ê²½ ì„¤ì •
# =========================================

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
# íŒŒì¼ì´ ê°™ì€ í´ë”ì— ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê²½ë¡œ ëª…ì‹œ ì§€ì •
env_path = os.path.join(PROJECT_ROOT, ".env")
load_dotenv(env_path)

if os.getenv("OPENAI_API_KEY"):
    print("âœ… .env íŒŒì¼ë¡œë¶€í„° API Keyë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
else:
    print("âš ï¸ .env íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

DB_PATH = os.path.join(PROJECT_ROOT, "data", "chroma_db")
# ëŒ€í™” ì´ë ¥ SQLite ê²½ë¡œ
CHAT_DB_PATH = os.path.join(PROJECT_ROOT, "data", "chat_log.sqlite")
# TTS ì…ë ¥ ê²½ë¡œì™€ ì¶œë ¥ ê²½ë¡œë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬í•´ ë³€ê²½ ì§€ì ì„ ë‹¨ì¼í™”í•œë‹¤.
TTS_MODEL_PATH = Path(PROJECT_ROOT) / "models" / "melo_yae" / "melo_yae.onnx"
TTS_BERT_PATH = Path(PROJECT_ROOT) / "models" / "melo_yae" / "bert_kor.onnx"
TTS_CONFIG_PATH = Path(PROJECT_ROOT) / "models" / "melo_yae" / "config.json"

# SQLite ì €ì¥ì†Œ
CHAT_STORE = SessionMemoryStore(CHAT_DB_PATH)

# ==========================================
# 1. í™”ë©´ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì…ì°°ë©”ì´íŠ¸ AI (Hybrid)", page_icon="ğŸ¤–", layout="wide")

st.title("ì…ì°°/ê³µê³  ë¶„ì„ AI: ì…ì°°ë©”ì´íŠ¸ (Hybrid Edition)")

# ì„¸ì…˜ ìƒíƒœ ê¸°ë³¸ê°’ì„ ë¨¼ì € ì´ˆê¸°í™”í•œë‹¤. (ì‚¬ì´ë“œë°”/ë©”ì¸ ê³µìš©)
st.session_state.setdefault("messages", [])
st.session_state.setdefault("last_answer_ready", False)
st.session_state.setdefault("last_q", None)
st.session_state.setdefault("last_a", None)
st.session_state.setdefault("last_tts_path", None)
st.session_state.setdefault("just_answered", False)

# ==========================================
# 2. ì‚¬ì´ë“œë°” (ì„¤ì •)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ í™˜ê²½ ì„¤ì •")

    if "OPENAI_API_KEY" not in os.environ:
        api_key = st.text_input("OpenAI API Key ì…ë ¥", type="password")
        if api_key:
            os.environ["OPENAI_API_KEY"] = api_key
            st.success("API Key ì €ì¥ ì™„ë£Œ!")

    st.subheader("ëª¨ë¸ ì„ íƒ")
    model_options = ["gpt-5-mini", "gpt-5-nano", "gpt-5"]
    selected_model = st.selectbox("ì‚¬ìš©í•  ëª¨ë¸", model_options, index=0)

    st.subheader("ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì„¤ì •")
    dense_weight = st.slider(
        "Dense(ì˜ë¯¸) ë¹„ì¤‘",
        0.0,
        1.0,
        0.6,
        0.1,
        help="ë†’ì„ìˆ˜ë¡ ë¬¸ë§¥ ìœ„ì£¼, ë‚®ì„ìˆ˜ë¡ í‚¤ì›Œë“œ ìœ„ì£¼",
    )
    sparse_weight = round(1.0 - dense_weight, 1)
    st.caption(f"Sparse(í‚¤ì›Œë“œ) ë¹„ì¤‘: {sparse_weight}")

    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°"):
        st.session_state.messages = []
        st.rerun()

    st.divider()
    st.subheader("ìŒì„± ì¬ìƒ")
    audio_placeholder = st.empty()

    if st.session_state.last_tts_path:
        audio_placeholder.empty()
        audio_placeholder.audio(
            st.session_state.last_tts_path,
            format="audio/wav",
        )
    else:
        audio_placeholder.caption("ì¬ìƒí•  ìŒì„±ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    st.subheader("í”¼ë“œë°±")
    if (
        st.session_state.last_answer_ready
        and st.session_state.last_q
        and st.session_state.last_a
    ):
        col_like, col_dislike = st.columns(2)
        with col_like:
            if st.button("ğŸ‘ ì¢‹ì•„ìš”"):
                ok = CHAT_STORE.update_rating(
                    st.session_state.last_q,
                    st.session_state.last_a,
                    1,
                )
                st.toast("ì €ì¥ ì™„ë£Œ" if ok else "ì €ì¥í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with col_dislike:
            if st.button("ğŸ‘ ì‹«ì–´ìš”"):
                ok = CHAT_STORE.update_rating(
                    st.session_state.last_q,
                    st.session_state.last_a,
                    -1,
                )
                st.toast("ì €ì¥ ì™„ë£Œ" if ok else "ì €ì¥í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.caption("ë‹µë³€ì´ ìƒì„±ëœ í›„ í”¼ë“œë°±ì„ ë‚¨ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# ==========================================
# 3. RAG ì²´ì¸ ì„¤ì • (Hybrid & LCEL Fix)
# ==========================================
@st.cache_resource(show_spinner="Hybrid ê²€ìƒ‰ ì—”ì§„ ê°€ë™ ì¤‘...")
def load_rag_chain(model_name, dense_w, sparse_w):

    if not os.path.exists(DB_PATH):
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—†ìŒ: {DB_PATH}")
        return None

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # 1. Dense Retriever (Chroma)
    vectorstore = Chroma(
        persist_directory=DB_PATH,
        embedding_function=embeddings,
        collection_name="bid_rfp_collection",
    )

    dense_retriever = vectorstore.as_retriever(
        search_type="mmr", search_kwargs={"k": 5, "fetch_k": 20}
    )

    # 2. Sparse Retriever (BM25)
    try:
        raw_docs = vectorstore.get()
        docs = []
        for i in range(len(raw_docs["ids"])):
            if raw_docs["documents"][i]:
                docs.append(
                    Document(
                        page_content=raw_docs["documents"][i],
                        metadata=(
                            raw_docs["metadatas"][i] if raw_docs["metadatas"] else {}
                        ),
                    )
                )

        if not docs:
            st.error("DBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        sparse_retriever = BM25Retriever.from_documents(docs)
        sparse_retriever.k = 5

    except Exception as e:
        st.error(f"BM25 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

    # 3. Ensemble Retriever (Hybrid)
    ensemble_retriever = EnsembleRetriever(
        retrievers=[dense_retriever, sparse_retriever], weights=[dense_w, sparse_w]
    )

    try:
        llm = ChatOpenAI(model=model_name, temperature=0)
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

    # [í”„ë¡¬í”„íŠ¸ 1] ì§ˆë¬¸ ì¬êµ¬ì„± (ë…ë¦½ì  ì§ˆë¬¸ ìƒì„±)
    context_q_system_prompt = """
    ì±„íŒ… ê¸°ë¡ê³¼ ìµœì‹  ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, ì±„íŒ… ê¸°ë¡ ì—†ì´ë„ ì´í•´í•  ìˆ˜ ìˆëŠ” 
    'ë…ë¦½ì ì¸ ì§ˆë¬¸'ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”. ë‹µë³€í•˜ì§€ ë§ê³  ì§ˆë¬¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
    """
    context_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", context_q_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    # Chain: (Dict) -> (String)
    history_aware_chain = context_q_prompt | llm | StrOutputParser()

    # [í”„ë¡¬í”„íŠ¸ 2] ë‹µë³€ ìƒì„± (QA)
    qa_system_prompt = """
    ë‹¹ì‹ ì€ ê³µê³µ ì…ì°°(RFP) ë¶„ì„ ì „ë¬¸ê°€ 'ì…ì°°ë©”ì´íŠ¸'ì…ë‹ˆë‹¤.
    ì•„ë˜ì˜ [ê²€ìƒ‰ëœ ë¬¸ì„œ]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

    ê·œì¹™:
    1. ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì‹¤ë§Œ ë‹µë³€í•˜ê³ , ëª¨ë¥´ë©´ "ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  í•˜ì„¸ìš”.
    2. ì˜ˆì‚°, ê¸°ê°„, ë‚ ì§œ ë“± ìˆ«ìë¥¼ ê¸°ì¬í•˜ì„¸ìš”. (ìˆ«ì í‘œê¸° ê·œì¹™ ì°¸ê³ )
    3. ë‹µë³€ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. ëª©ë¡/ë¶ˆë¦¿/í‘œëŠ” ì“°ì§€ ë§ˆì„¸ìš”.
    4. ë‹µë³€ì€ ì¡´ëŒ“ë§ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    5. ë¬¸ì¥ì€ ê¸¸ì§€ ì•Šê²Œ ëŠì–´ ì½ê¸° ì‰¬ìš´ ê¸¸ì´ë¡œ ìœ ì§€í•˜ì„¸ìš”.
    6. ë¬¸ë‹¨ì€ 2~3ë¬¸ì¥ë§ˆë‹¤ ë¹ˆ ì¤„(ê°œí–‰ 2ê°œ)ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
    7. ê´„í˜¸ëŠ” ì“°ì§€ ë§ê³ , ëª©ë¡/í—¤ë”/ì»¨í…ìŠ¤íŠ¸ ì¸ìš©ì€ ë¬¸ì¥ìœ¼ë¡œ í’€ì–´ ì‘ì„±í•˜ì„¸ìš”.
    8. íŠ¹ìˆ˜ë¬¸ì(% ë“±)ëŠ” í•œêµ­ì–´ë¡œ í’€ì–´ì„œ ì“°ì„¸ìš”.
    9. ì¶œë ¥ì€ 10ì¤„ì„ ë„˜ê¸°ì§€ ì•Šê²Œ í•˜ì„¸ìš”.

    ì˜ì–´ í‘œê¸° ê·œì¹™:
    - ì˜ì–´ ë‹¨ì–´ëŠ” í•œêµ­ì–´ ìŒì—­ìœ¼ë¡œë§Œ í‘œê¸°í•˜ì„¸ìš”.
    - ì˜ˆ: dashboard -> ëŒ€ì‹œë³´ë“œ, dataset -> ë°ì´í„°ì…‹, isp -> ì•„ì´ì—ìŠ¤í”¼, system -> ì‹œìŠ¤í…œ.

    ìˆ«ì í‘œê¸° ê·œì¹™:
    - ê¸ˆì•¡ì€ ë°˜ë“œì‹œ í•œê¸€ í™”íì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    - ì˜ˆ: 35,750,000ì› -> 3ì²œ 5ë°± 7ì‹­ 5ë§Œì›
    - ë‚ ì§œëŠ” 'YYYYë…„ MMì›” DDì¼' í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    - ì˜ˆ: 2024-06-24 11:00:00 -> 2024ë…„ 6ì›” 24ì¼
    - ê¸°ê°„ì€ 'Nê°œì›”', 'Nì£¼', 'Nì¼' í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

    [ê²€ìƒ‰ëœ ë¬¸ì„œ]:
    {context}
    """
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", qa_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    # ê²€ìƒ‰ ì¿¼ë¦¬ ê²°ì • í•¨ìˆ˜
    def get_search_query(input_dict):
        if input_dict.get("chat_history"):
            # ëŒ€í™” ê¸°ë¡ì´ ìˆìœ¼ë©´ ì¬êµ¬ì„± ì²´ì¸ ì‹¤í–‰ (String ë°˜í™˜)
            return history_aware_chain.invoke(input_dict)
        else:
            # ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ ê·¸ëŒ€ë¡œ ì‚¬ìš© (String ë°˜í™˜)
            return input_dict["input"]

    # ì²´ì¸ ì¡°ë¦½
    def format_docs(docs):
        return "\n\n".join([d.page_content for d in docs])

    setup_and_retrieval = RunnableParallel(
        {
            # RunnableLambdaë¡œ ê°ì‹¸ì„œ ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ ì „ë‹¬
            "context": RunnableLambda(get_search_query) | ensemble_retriever,
            "input": lambda x: x["input"],
            "chat_history": lambda x: x["chat_history"],
        }
    )

    # ìµœì¢… ì²´ì¸
    rag_chain = setup_and_retrieval.assign(
        answer=RunnablePassthrough.assign(context=lambda x: format_docs(x["context"]))
        | qa_prompt
        | llm
        | StrOutputParser()
    )

    return rag_chain


# ==========================================
# 4. TTS ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def split_sentences_buffered(buffer: str) -> tuple[list[str], str]:
    # ì†Œìˆ˜ì  ë³´í˜¸
    protected = re.sub(r"(?<=\d)\.(?=\d)", "<DOT>", buffer)

    sentences: list[str] = []
    buf: list[str] = []
    i = 0
    while i < len(protected):
        ch = protected[i]
        buf.append(ch)

        # ë¬¸ì¥ êµ¬ë‘ì  ê¸°ì¤€ ë¶„ë¦¬
        if ch in ".!?ã€‚ï¼ï¼Ÿ":
            sentence = "".join(buf).replace("<DOT>", ".").strip()
            if sentence:
                sentences.append(sentence)
            buf = []
            i += 1
            continue

        # ì¤„ë°”ê¿ˆ/ë¬¸ë‹¨ ê²½ê³„ ê¸°ì¤€ ë¶„ë¦¬
        if ch == "\n":
            # ì—°ì† ê°œí–‰ì„ í•˜ë‚˜ì˜ ê²½ê³„ë¡œ ì²˜ë¦¬
            while i + 1 < len(protected) and protected[i + 1] == "\n":
                i += 1
                buf.append("\n")
            sentence = "".join(buf).replace("<DOT>", ".").strip()
            if sentence:
                sentences.append(sentence)
            buf = []
        i += 1

    remainder = "".join(buf).replace("<DOT>", ".").strip()
    return [s for s in sentences if s], remainder


def _split_sentences_for_tts(text: str) -> list[str]:
    # buffered splitterë¥¼ ë‹¨ë°œ ì…ë ¥ì— ë§ê²Œ ë˜í•‘í•œë‹¤.
    sentences, remainder = split_sentences_buffered(text)
    if remainder:
        sentences.append(remainder)
    return sentences


def _is_junk_line(line: str) -> bool:
    stripped = re.sub(r"[^0-9A-Za-zê°€-í£]", "", line)
    if not stripped:
        return True
    if stripped.isdigit():
        return True
    digit_ratio = sum(ch.isdigit() for ch in stripped) / max(len(stripped), 1)
    if digit_ratio > 0.4:
        return True
    if len(stripped) < 4:
        return True
    return False


def _sanitize_answer(text: str) -> str:
    cleaned_lines = []
    for line in text.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        if stripped.startswith("ì»¨í…ìŠ¤íŠ¸") or stripped.startswith("[Source"):
            continue
        if _is_junk_line(stripped):
            continue
        cleaned_lines.append(stripped)
    cleaned = " ".join(cleaned_lines)
    cleaned = re.sub(r"\([^)]*\)", "", cleaned)
    cleaned = re.sub(r"\[[^\]]*\]", "", cleaned)
    cleaned = re.sub(r"[^0-9A-Za-zê°€-í£\s,\.\!\?]", " ", cleaned)
    cleaned = re.sub(r"\d{20,}", "", cleaned)
    cleaned = re.sub(r"\s+", " ", cleaned).strip()
    return cleaned


def _select_audio_player(preferred: str | None = None) -> list[str] | None:
    if preferred in {"none", "off"}:
        return None
    if preferred in {"ffplay"}:
        path = shutil.which(preferred)
        if not path:
            return None
        return [path, "-autoexit", "-nodisp", "-loglevel", "error"]
    if preferred in {"mpv"}:
        path = shutil.which(preferred)
        if not path:
            return None
        return [path, "--ao=pulse", "--no-video", "--quiet", "--keep-open=no"]
    for candidate in ("ffplay",):
        path = shutil.which(candidate)
        if not path:
            continue
        return [path, "-autoexit", "-nodisp", "-loglevel", "error"]
    return None


# ==========================================
# 5. íƒ­ ì¸í„°í˜ì´ìŠ¤
# ==========================================

tab1, tab2 = st.tabs(["PDF ë·°ì–´", "ì±„íŒ…"])

# ------------------------------------------
# Tab 1: PDF ë·°ì–´
# ------------------------------------------
with tab1:
    PDF_DIR = os.path.join(PROJECT_ROOT, "data", "pdf")
    pdf_files = sorted(glob.glob(os.path.join(PDF_DIR, "*.pdf")))

    if not pdf_files:
        st.warning(f"PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {PDF_DIR}")
    else:
        for pdf_path in pdf_files:
            pdf_name = os.path.basename(pdf_path)
            st.subheader(pdf_name)

            doc = fitz.open(pdf_path)
            total_pages = len(doc)

            page_key = f"page_{pdf_name}"
            slider_key = f"slider_{pdf_name}"
            st.session_state.setdefault(page_key, 1)

            def _on_slider_change(_pk=page_key, _sk=slider_key):
                st.session_state[_pk] = st.session_state[_sk]

            # í˜ì´ì§€ ì´ë™
            def _go_prev(_pk=page_key, _sk=slider_key):
                if st.session_state[_pk] > 1:
                    st.session_state[_pk] -= 1
                    st.session_state[_sk] = st.session_state[_pk]

            try:
                player_cmd = _select_audio_player("mpv")
            except Exception as e:
                st.error(f"ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì„ íƒ ì‹¤íŒ¨: {e}")

            def _go_next(_pk=page_key, _sk=slider_key, _tp=total_pages):
                if st.session_state[_pk] < _tp:
                    st.session_state[_pk] += 1
                    st.session_state[_sk] = st.session_state[_pk]

            col_left, col_info, col_right = st.columns([1, 3, 1])
            with col_left:
                st.button("â—€ ì´ì „", key=f"prev_{pdf_name}", on_click=_go_prev)
            with col_info:
                st.markdown(f"**{st.session_state[page_key]} / {total_pages} í˜ì´ì§€**")
            with col_right:
                st.button("ë‹¤ìŒ â–¶", key=f"next_{pdf_name}", on_click=_go_next)

            st.slider(
                "í˜ì´ì§€ ì´ë™",
                1,
                total_pages,
                st.session_state[page_key],
                key=slider_key,
                on_change=_on_slider_change,
            )

            page_num = st.session_state[page_key] - 1
            page = doc[page_num]
            pix = page.get_pixmap(dpi=150)
            img_bytes = pix.tobytes("png")

            st.image(img_bytes, width="stretch")
            doc.close()
            st.divider()

    # í‚¤ë³´ë“œ ì¢Œ/ìš° í™”ì‚´í‘œë¡œ í˜ì´ì§€ ë„˜ê¸°ê¸°
    st.components.v1.html(
        """
    <script>
    const doc = window.parent.document;
    doc.addEventListener('keydown', function(e) {
        if (e.target.tagName === 'INPUT' || e.target.tagName === 'TEXTAREA') return;
        if (e.key === 'ArrowLeft') {
            const btn = doc.querySelectorAll('button');
            for (const b of btn) {
                if (b.innerText.includes('ì´ì „')) { b.click(); break; }
            }
        } else if (e.key === 'ArrowRight') {
            const btn = doc.querySelectorAll('button');
            for (const b of btn) {
                if (b.innerText.includes('ë‹¤ìŒ')) { b.click(); break; }
            }
        }
    });
    </script>
    """,
        height=0,
    )

# ------------------------------------------
# Tab 2: ì±„íŒ…
# ------------------------------------------
with tab2:
    st.markdown(
        """
- **Dense(ì˜ë¯¸)**: ë¬¸ë§¥ê³¼ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê²€ìƒ‰ (Chroma)
- **Sparse(í‚¤ì›Œë“œ)**: ê³µê³  ë²ˆí˜¸, ì˜ˆì‚°, ëª¨ë¸ëª… ë“± ì •í™•í•œ ë§¤ì¹­ ê²€ìƒ‰ (BM25)
"""
    )

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "last_answer_ready" not in st.session_state:
        st.session_state.last_answer_ready = False
    if "last_q" not in st.session_state:
        st.session_state.last_q = None
    if "last_a" not in st.session_state:
        st.session_state.last_a = None

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):

        if "OPENAI_API_KEY" not in os.environ:
            st.warning("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()

        st.session_state.messages.append({"role": "user", "content": query})
        st.session_state.last_answer_ready = False
        st.session_state.last_q = None
        st.session_state.last_a = None
        with st.chat_message("user"):
            st.markdown(query)

        with st.chat_message("assistant"):
            chain = load_rag_chain(selected_model, dense_weight, sparse_weight)

            if chain:
                history_langchain = []
                for msg in st.session_state.messages[:-1]:
                    if msg["role"] == "user":
                        history_langchain.append(HumanMessage(content=msg["content"]))
                    else:
                        history_langchain.append(AIMessage(content=msg["content"]))

                message_placeholder = st.empty()
                full_response = ""
                source_docs = []

                try:
                    player_cmd = _select_audio_player("ffplay")

                    full_response = ""
                    source_documents = []
                    tts_buffer = ""
                    out_dir = os.path.join(PROJECT_ROOT, "data", "answer")
                    os.makedirs(out_dir, exist_ok=True)

                    # ìƒˆ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ê¸°ì¡´ TTS ì¬ìƒì„ ì¤‘ë‹¨í•˜ê³  íë¥¼ ë¹„ìš´ë‹¤.
                    if _TTS_WORKER is not None:
                        _TTS_WORKER.cancel()

                    tts_worker = TTSWorker(
                        model_path=TTS_MODEL_PATH,
                        bert_path=TTS_BERT_PATH,
                        config_path=TTS_CONFIG_PATH,
                        out_dir=out_dir,
                        device="cpu",
                        player_cmd=player_cmd,
                        sanitize_fn=_sanitize_answer,
                        split_fn=_split_sentences_for_tts,
                    )
                    tts_worker.start()
                    _TTS_WORKER = tts_worker

                    for chunk in chain.stream(
                        {"input": query, "chat_history": history_langchain}
                    ):
                        if "answer" in chunk:
                            text = chunk["answer"]
                            full_response += text
                            tts_buffer += text

                            sentences, tts_buffer = split_sentences_buffered(tts_buffer)
                            for sent in sentences:
                                tts_worker.enqueue(sent)
                            message_placeholder.markdown(full_response + "â–Œ")

                        if "context" in chunk:
                            source_docs = chunk["context"]

                    if tts_buffer.strip():
                        sentences, remainder = split_sentences_buffered(
                            tts_buffer.strip()
                        )
                        for sent in sentences:
                            tts_worker.enqueue(sent)
                        if remainder:
                            tts_worker.enqueue(remainder)

                    tts_worker.close()
                    last_path = tts_worker.last_path()
                    if last_path:
                        st.session_state.last_tts_path = last_path
                        audio_placeholder.empty()
                        audio_placeholder.audio(
                            st.session_state.last_tts_path,
                            format="audio/wav",
                        )

                    message_placeholder.markdown(full_response)

                    # ì§ˆë¬¸/ë‹µë³€ ì €ì¥ (ratingì€ NULL)
                    CHAT_STORE.save_turn(query, full_response)
                    st.session_state.last_answer_ready = True
                    st.session_state.last_q = query
                    st.session_state.last_a = full_response
                    st.session_state.just_answered = True

                    if source_docs:
                        with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ í™•ì¸í•˜ê¸° (Hybrid ê²€ìƒ‰)"):
                            seen = set()
                            for i, doc in enumerate(source_docs):
                                source = os.path.basename(
                                    doc.metadata.get("source", "Unknown")
                                )
                                page = doc.metadata.get("page", 0)
                                preview = doc.page_content[:40].replace("\n", " ")

                                key = f"{source}p{page}"
                                if key not in seen:
                                    st.markdown(f"**{i+1}. {source}** (Page {page+1})")
                                    st.caption(f"ë‚´ìš©: {preview}...")
                                    seen.add(key)

                    st.session_state.messages.append(
                        {"role": "assistant", "content": full_response}
                    )

                except Exception as e:
                    st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")

        if st.session_state.just_answered:
            st.session_state.just_answered = False
            st.rerun()
