# extract_tables_to_md.py
# ============================================
# pdf_out/*.pdf â†’ VLM í‘œ ì¶”ì¶œ â†’ final_docs/*.mdì— í˜ì´ì§€ë³„ ì‚½ì…
#
# ê°œì„ :
# - JSONDecodeError(Invalid control character) ë°©ì§€/ë³µêµ¬
# - response_format json_object(ì§€ì› ì‹œ)ë¡œ JSON ê°•ì œ
# - íŒŒì‹± ì‹¤íŒ¨/í˜¸ì¶œ ì‹¤íŒ¨ëŠ” "í˜ì´ì§€ ìŠ¤í‚µ + ë¡œê·¸" (ì „ì²´ ì¤‘ë‹¨ ë°©ì§€)
# - JPEG + DPI ë Œë”ë§ + concurrency ì œí•œ + gc
# - ENOSPC(ë””ìŠ¤í¬ ë¶€ì¡±) ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
# ============================================

import asyncio
import base64
import errno
import gc
import json
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import fitz  # PyMuPDF
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()

# -------- ê²½ë¡œ ì„¤ì • --------
PDF_DIR = Path("pdf_out")
MD_DIR = Path("final_docs")

# -------- OpenAI ì„¤ì • --------
client = AsyncOpenAI()
MODEL = "gpt-5-mini"

SYSTEM_PROMPT = """
ë„ˆëŠ” ë¬¸ì„œ í˜ì´ì§€ì—ì„œ 'í‘œ'ë§Œ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ë‹¤.

ê·œì¹™:
- ë³´ì´ëŠ” í‘œë§Œ ì¶”ì¶œí•œë‹¤ (ì¶”ì¸¡ ê¸ˆì§€)
- í‘œëŠ” Markdown tableë¡œ ë³€í™˜í•œë‹¤
- í‘œê°€ ì—†ìœ¼ë©´ {"tables": []} ë§Œ ë°˜í™˜í•œë‹¤
- ì„¤ëª… ë¬¸ì¥ì€ ì“°ì§€ ì•ŠëŠ”ë‹¤
- JSONë§Œ ì¶œë ¥í•œë‹¤

ì¶œë ¥ í˜•ì‹:
{
  "tables": [
    {
      "caption": "í‘œ ì œëª© (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
      "markdown": "| ... |"
    }
  ]
}
"""

# -------- ì„±ëŠ¥/ë¶€í•˜ íŠœë‹ --------
DPI = 140               # 120~160 ê¶Œì¥
IMG_FORMAT = "jpeg"     # "jpeg" ì¶”ì²œ
CONCURRENCY = 4         # 3~5 ê¶Œì¥
RETRY = 1               # 1~2 ê¶Œì¥
SLEEP_SEC = 0.6         # ì¬ì‹œë„ backoff base
GC_EVERY = 15           # Ní˜ì´ì§€ë§ˆë‹¤ gc

# -------- ë¡œê·¸ ì €ì¥ --------
LOG_DIR = Path("logs_tables")
LOG_DIR.mkdir(exist_ok=True)

# =========================
# 1) JSON íŒŒì‹±(ê°•í™”)
# =========================
_CONTROL_CHARS_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F]")

def safe_json_loads(s: str) -> Dict[str, Any]:
    """
    ëª¨ë¸ì´ ```json ...``` í˜¹ì€ ì•/ë’¤ì— í…ìŠ¤íŠ¸ë¥¼ ì„ê±°ë‚˜,
    ì œì–´ë¬¸ì(Invalid control character)ê°€ ë“¤ì–´ê°€ë„ ìµœëŒ€í•œ ë³µêµ¬í•´ì„œ íŒŒì‹±.
    """
    s = (s or "").strip()

    # ì½”ë“œíœìŠ¤ ì œê±°
    s = re.sub(r"^```json\s*|\s*```$", "", s, flags=re.IGNORECASE).strip()

    # ê°€ì¥ ë°”ê¹¥ { ... } ë§Œ ê³¨ë¼ë‚´ê¸°
    m = re.search(r"\{.*\}", s, flags=re.DOTALL)
    if m:
        s = m.group(0)

    # ì œì–´ë¬¸ì ì œê±°(ê°€ì¥ í”í•œ JSONDecodeError ì›ì¸)
    s = _CONTROL_CHARS_RE.sub("", s)

    return json.loads(s)

# =========================
# 2) í˜ì´ì§€ â†’ data URL
# =========================
def page_to_data_url(page, dpi: int = DPI, img_format: str = IMG_FORMAT) -> str:
    pix = page.get_pixmap(dpi=dpi, alpha=False)

    if img_format.lower() == "png":
        raw = pix.tobytes("png")
        mime = "image/png"
    else:
        raw = pix.tobytes("jpeg")
        mime = "image/jpeg"

    del pix
    b64 = base64.b64encode(raw).decode("utf-8")
    return f"data:{mime};base64,{b64}"

# =========================
# 3) VLM í˜¸ì¶œ (JSON ëª¨ë“œ ì‹œë„ â†’ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ í˜¸ì¶œ)
# =========================
async def call_vlm_tables(img_url: str, page_no: int) -> str:
    """
    output_text(str)ë§Œ ë°˜í™˜.
    response_format json_objectë¥¼ ë¨¼ì € ì‹œë„í•˜ê³ ,
    ëª¨ë¸/í™˜ê²½ì´ ê±°ë¶€í•˜ë©´ fallback.
    """
    # 1) JSON ëª¨ë“œ ì‹œë„
    try:
        resp = await client.responses.create(
            model=MODEL,
            response_format={"type": "json_object"},
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": SYSTEM_PROMPT}]},
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": f"{page_no}í˜ì´ì§€ì—ì„œ í‘œë§Œ ì¶”ì¶œí•´."},
                        {"type": "input_image", "image_url": img_url},
                    ],
                },
            ],
        )
        return resp.output_text
    except Exception:
        # 2) fallback: ì¼ë°˜ í˜¸ì¶œ
        resp = await client.responses.create(
            model=MODEL,
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": SYSTEM_PROMPT}]},
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": f"{page_no}í˜ì´ì§€ì—ì„œ í‘œë§Œ ì¶”ì¶œí•´."},
                        {"type": "input_image", "image_url": img_url},
                    ],
                },
            ],
        )
        return resp.output_text

async def extract_tables_from_page(page, page_no: int, pdf_name: str) -> Dict[str, Any]:
    """
    - retry í¬í•¨
    - JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ: tables=[]ë¡œ ë°˜í™˜ + ë¡œê·¸ ì €ì¥ (ì „ì²´ ì¤‘ë‹¨ ë°©ì§€)
    """
    img_url = page_to_data_url(page, dpi=DPI)

    last_err: Optional[Exception] = None
    last_raw: Optional[str] = None

    for attempt in range(RETRY + 1):
        try:
            raw = await call_vlm_tables(img_url, page_no)
            last_raw = raw

            try:
                return safe_json_loads(raw)
            except json.JSONDecodeError as je:
                # JSON ê¹¨ì§ â†’ í˜ì´ì§€ ìŠ¤í‚µ ì²˜ë¦¬, raw ë¡œê·¸ ì €ì¥
                log_path = LOG_DIR / f"jsondecode_{pdf_name}_p{page_no}.txt"
                log_path.write_text(raw or "", encoding="utf-8")
                return {"tables": [], "_error": f"JSONDecodeError: {repr(je)}", "_raw_saved": str(log_path)}

        except Exception as e:
            last_err = e
            await asyncio.sleep(SLEEP_SEC * (attempt + 1))

    # í˜¸ì¶œ ìì²´ ì‹¤íŒ¨ â†’ í˜ì´ì§€ ìŠ¤í‚µ + ì—ëŸ¬ ë¡œê·¸
    if last_raw:
        log_path = LOG_DIR / f"callfail_{pdf_name}_p{page_no}.txt"
        log_path.write_text(last_raw, encoding="utf-8")

    return {"tables": [], "_error": f"call_failed: {repr(last_err)}"}

# =========================
# 4) MD ì‚½ì…(êµì²´ ë°©ì‹)
# =========================
def insert_tables_into_md(md_path: Path, tables_by_page: List[Dict[str, Any]]):
    if not md_path.exists():
        raise FileNotFoundError(md_path)

    text = md_path.read_text(encoding="utf-8")
    lines = text.splitlines()

    page_starts = []
    for idx, line in enumerate(lines):
        m = re.match(r"^\s*<!--\s*page:\s*(\d+)\s*-->\s*$", line.strip())
        if m:
            page_starts.append((int(m.group(1)), idx))

    if not page_starts:
        raise ValueError(f"MDì— <!-- page: N --> ì£¼ì„ì´ ì—†ìŠµë‹ˆë‹¤: {md_path}")

    page_starts_sorted = sorted(page_starts, key=lambda x: x[1])
    page_to_range = {}
    for k in range(len(page_starts_sorted)):
        page_no, start_idx = page_starts_sorted[k]
        end_idx = page_starts_sorted[k + 1][1] if k + 1 < len(page_starts_sorted) else len(lines)
        page_to_range[page_no] = (start_idx, end_idx)

    tables_map = {item["page"]: item.get("tables", []) for item in tables_by_page}

    new_lines = lines[:]
    for page_no in sorted(tables_map.keys(), reverse=True):
        if page_no not in page_to_range:
            continue

        start_idx, end_idx = page_to_range[page_no]
        block = new_lines[start_idx:end_idx]

        start_tag = f"<!-- tables: start page {page_no} -->"
        end_tag = f"<!-- tables: end page {page_no} -->"

        # ê¸°ì¡´ ë¸”ë¡ ì œê±°(ì¬ì‹¤í–‰ ì¤‘ë³µ ë°©ì§€)
        if start_tag in block and end_tag in block:
            s = block.index(start_tag)
            e = block.index(end_tag)
            block = block[:s] + block[e + 1 :]

        tables = tables_map.get(page_no, [])
        if not tables:
            new_lines[start_idx:end_idx] = block
            continue

        while block and block[-1].strip() == "":
            block.pop()

        insert = ["", start_tag]
        for t in tables:
            caption = (t.get("caption") or "").strip()
            md_table = (t.get("markdown") or "").strip()
            if caption:
                insert.append(f"**[í‘œ] {caption}**")
            if md_table:
                insert.append(md_table)
            insert.append("")
        insert.extend([end_tag, ""])
        new_lines[start_idx:end_idx] = block + insert

    md_path.write_text("\n".join(new_lines), encoding="utf-8")

# =========================
# 5) PDF í•˜ë‚˜ ì²˜ë¦¬
# =========================
async def process_one_pdf(pdf_path: Path, concurrency: int = CONCURRENCY, progress_every: int = 10):
    md_path = MD_DIR / f"{pdf_path.stem}.md"
    if not md_path.exists():
        raise FileNotFoundError(f"MD ì—†ìŒ: {md_path}")

    doc = fitz.open(pdf_path)
    tables_by_page: List[Dict[str, Any]] = []

    sem = asyncio.Semaphore(concurrency)
    pdf_name_safe = re.sub(r"[^0-9A-Za-zê°€-í£._-]+", "_", pdf_path.stem)

    async def run_page(i: int) -> Tuple[int, List[Dict[str, Any]]]:
        page_no = i + 1
        page = doc.load_page(i)
        try:
            async with sem:
                tables_json = await extract_tables_from_page(page, page_no=page_no, pdf_name=pdf_name_safe)

            tables = []
            if isinstance(tables_json, dict):
                tables = tables_json.get("tables", []) or []

            return (page_no, tables)
        finally:
            del page

    tasks = [asyncio.create_task(run_page(i)) for i in range(doc.page_count)]
    done_count = 0

    for coro in asyncio.as_completed(tasks):
        page_no, tables = await coro
        done_count += 1

        if tables:
            tables_by_page.append({"page": page_no, "tables": tables})

        if progress_every and (done_count % progress_every == 0):
            print(f"{pdf_path.name}: {done_count}/{doc.page_count} (tables pages so far: {len(tables_by_page)})")

        if GC_EVERY and (done_count % GC_EVERY == 0):
            gc.collect()

    doc.close()

    tables_by_page.sort(key=lambda x: x["page"])
    insert_tables_into_md(md_path, tables_by_page)

    print(f"âœ… ì™„ë£Œ: {pdf_path.name} â†’ {md_path.name} (í‘œ ìˆëŠ” í˜ì´ì§€: {len(tables_by_page)}ê°œ)")
    return md_path, tables_by_page

# =========================
# 6) main
# =========================
def main():
    pdfs = sorted(PDF_DIR.glob("*.pdf"))
    assert pdfs, f"{PDF_DIR} í´ë”ì— PDFê°€ ì—†ìŠµë‹ˆë‹¤."

    for pdf_path in pdfs:
        try:
            asyncio.run(process_one_pdf(pdf_path, concurrency=CONCURRENCY, progress_every=10))
        except OSError as e:
            if getattr(e, "errno", None) == errno.ENOSPC or "No space left" in str(e):
                print(f"ğŸ’¥ ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±(ENOSPC). ì¦‰ì‹œ ì¤‘ë‹¨: {pdf_path.name}")
                raise
            print(f"âŒ ì‹¤íŒ¨: {pdf_path.name} / ì—ëŸ¬: {repr(e)}")
        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨: {pdf_path.name} / ì—ëŸ¬: {repr(e)}")

if __name__ == "__main__":
    main()
